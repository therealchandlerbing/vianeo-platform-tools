# VIANEO Complete Business Model Evaluation System

**AI-Assisted Systematic Startup Assessment Framework**

## System Overview

This is a comprehensive 8-step business model evaluation system using the VIANEO methodology. It transforms raw startup applications into complete assessments across five interconnected dimensions: **Legitimacy (15%)**, **Desirability (25%)**, **Acceptability (20%)**, **Feasibility (20%)**, and **Viability (20%)**.

## When to Use This System

**For Accelerators/Incubators:**
- Evaluating startup applications
- Creating structured cohort comparisons
- Tracking progress through program milestones

**For Investors:**
- Conducting due diligence on ventures
- Comparing deal flow opportunities
- Identifying investment risks systematically

**For Advisors/Mentors:**
- Providing structured feedback to founders
- Identifying critical gaps requiring attention
- Tracking validation progress over time

**For Founders:**
- Self-assessment of business readiness
- Identifying evidence gaps before fundraising
- Prioritizing validation activities

---

## The Complete 8-Step Workflow

```
INPUT: Startup application, pitch deck, or business plan
  â†“
STEP 0: Canvas Extraction (20-30 min)
  â†’ Structured business model canvas
  â†“
STEP 1: Application Forms [OPTIONAL] (15 min)
  â†’ Standardized format for tracking
  â†“
STEP 2: 40-Question Diagnostic (30-45 min)
  â†’ Team, Technology, Management, Commercial scores
  â†“
STEP 3: 29-Question Market Maturity (45-60 min)
  â†’ Five dimensional scores with weighted total
  â†“
STEP 4: Legitimacy Deep Dive (20-30 min)
  â†’ Problem validation and domain fit analysis
  â†“
STEP 5: Desirability Analysis (30-40 min)
  â†’ User segments, needs, and personas
  â†“
STEP 6: Needs Qualification Matrix (45 min)
  â†’ Visual HTML heatmap of priority targets
  â†“
STEP 7: Ecosystem Mapping (30-45 min)
  â†’ Stakeholder analysis with acceptability ratings
  â†“
STEP 8: Network Visualization (60-90 min)
  â†’ Interactive HTML value network map
  â†“
OUTPUT: Complete evaluation package with committee report
```

**Total Time:**
- **Fast Track** (Steps 0, 2, 4, 5): 90 minutes
- **Standard** (Steps 0-7): 3-4 hours
- **Complete** (All steps 0-8): 5-6 hours

---

## Execution Paths

### Path 1: Fast Track Screening (90 minutes)

**Use For:** Initial cohort screening, quick go/no-go decisions

**Steps:** 0 â†’ 2 â†’ 4 â†’ 5

**Outputs:**
- Business model canvas
- Dimensional scores (no visuals)
- Key strengths and gaps
- Screening recommendation

**Best For:** Processing 10+ applications quickly

---

### Path 2: Standard Evaluation (3-4 hours)

**Use For:** Committee-ready evaluation of finalists

**Steps:** 0 â†’ 2 â†’ 3 â†’ 4 â†’ 5 â†’ 6 â†’ 7

**Outputs:**
- Complete canvas and diagnostics
- All five dimensional scores
- Needs qualification matrix (HTML)
- Ecosystem mapping
- Investment recommendation

**Best For:** Top 5 finalists requiring deep analysis

---

### Path 3: Complete Assessment (5-6 hours)

**Use For:** Executive presentation packages, major investments

**Steps:** All steps 0-8

**Outputs:**
- Everything from Standard path
- Interactive network visualization (HTML)
- Professional committee report
- Executive presentation deck ready

**Best For:** Series A+ due diligence, accelerator demo days

---

## The Five VIANEO Dimensions

### 1. Legitimacy (15% Weight, Threshold 3.0)

**Focus:** Is the problem real and significant?

**Key Questions:**
- Is the problem validated by external evidence?
- Is the field of application appropriate for this solution?
- Does the team have unique insight or approach?

**Evidence Required:**
- Multiple stakeholders confirming problem exists
- Data quantifying problem magnitude
- Domain expertise or personal connection to problem

**Red Flags:**
- Solution embedded in problem statement
- No external validation of problem
- Domain too broad or constantly shifting

---

### 2. Desirability (25% Weight, Threshold 3.5)

**Focus:** Do customers want this solution?

**Key Questions:**
- Have target users been interviewed (5+ per segment minimum)?
- Are user needs distinct and validated?
- Is there evidence of problem-solution fit?
- How does this compare to alternatives?

**Evidence Required:**
- Customer discovery interviews documented
- User testing with prototypes
- Competitive analysis with direct testing
- Validated willingness to pay

**Red Flags:**
- Zero customer interviews conducted
- Needs overlap or are solution-embedded
- Generic customer segments
- No competitive differentiation

---

### 3. Acceptability (20% Weight, Threshold 3.0)

**Focus:** Will the ecosystem support this?

**Key Questions:**
- Are all key stakeholders identified and mapped?
- What is their acceptability rating (favorable/neutral/unfavorable)?
- Are critical partners willing to collaborate?
- Are regulatory/influencer barriers identified and addressable?

**Evidence Required:**
- Ecosystem map with 10+ players
- Acceptability ratings validated through conversations
- Mitigation strategies for unfavorable players
- Partnership discussions initiated

**Red Flags:**
- Multiple unfavorable critical players
- No mitigation strategies for resistance
- Regulatory barriers unaddressed
- Key dependencies on unengaged parties

---

### 4. Feasibility (20% Weight, Threshold 3.0)

**Focus:** Can the team actually deliver this?

**Key Questions:**
- Does the team have necessary skills and experience?
- Is the technology proven or feasible?
- Are resources (financial, human, physical) secured or accessible?
- Is there a realistic implementation plan?

**Evidence Required:**
- Team completeness assessment
- Technical proof-of-concept or prototype
- Resource plan with commitments
- Development timeline with milestones

**Red Flags:**
- Critical skill gaps with no hiring plan
- Technical feasibility unproven
- No funding and unclear path to resources
- Unrealistic timelines

---

### 5. Viability (20% Weight, Threshold 3.0)

**Focus:** Is the business model sustainable?

**Key Questions:**
- Is the revenue model clearly defined?
- Has pricing been tested with customers?
- Is there a path to profitability?
- Are unit economics favorable?

**Evidence Required:**
- Business model canvas complete
- Pricing tested with 5+ potential customers
- Financial projections with validated assumptions
- Unit economics analysis (LTV:CAC ratio)

**Red Flags:**
- Revenue model undefined or untested
- No clear path to profitability
- Unit economics don't work
- Dependency on unproven monetization

---

## Using This System

### Prerequisites

**Required Materials:**
- Startup application, pitch deck, or business plan (PDF/Word/text)
- Any supplementary materials (research, prototypes, financials)
- 90 minutes to 6 hours (depending on execution path)

**Knowledge Requirements:**
- Basic understanding of business models
- Familiarity with the domain being evaluated
- Ability to distinguish assumptions from validated evidence

**Technical Setup:**
- AI assistant (Claude recommended) with access to all prompts
- Web browser for HTML visualizations
- Document editor for reports

---

### Getting Started

**Step 1: Choose Your Execution Path**

Ask yourself:
- How many startups am I evaluating? (Many = Fast Track)
- What's my decision timeline? (Days = Standard, Weeks = Complete)
- Who's my audience? (Internal = Fast, Committee = Standard, Board = Complete)

**Step 2: Gather Materials**

Collect from the startup:
- Application form or pitch deck
- Business plan (if available)
- Financial projections
- Customer validation evidence
- Prototype or demo access

**Step 3: Set Up Your Workspace**

Create folder structure:
```
[CompanyName]_Evaluation/
  â”œâ”€â”€ 00_Source_Materials/
  â”œâ”€â”€ 01_Canvas/
  â”œâ”€â”€ 02_Diagnostic/
  â”œâ”€â”€ 03_Market_Maturity/
  â”œâ”€â”€ 04_Legitimacy/
  â”œâ”€â”€ 05_Desirability/
  â”œâ”€â”€ 06_Needs_Matrix/
  â”œâ”€â”€ 07_Ecosystem/
  â”œâ”€â”€ 08_Network_Map/
  â””â”€â”€ 09_Final_Report/
```

**Step 4: Execute the Workflow**

Use the individual step prompts in the `prompts/` directory, working sequentially through your chosen execution path.

---

## Step-by-Step Guide

### STEP 0: Executive Brief Extraction (20-30 min)

**Purpose:** Transform unstructured materials into standardized Executive Brief format with strict character limits

**Prompt Location:** `prompts/step_0_executive_brief_extraction.md`

**Template Location:** `templates/Executive_Brief_Template.md`

**Structure - Executive Brief (B1-B7):**
- **B1:** Project Name + One-Line Description (MAX 150 chars)
- **B2:** Problem Statement (MAX 300 chars) - Solution-neutral
- **B3:** Proposed Solution (MAX 300 chars) - Approach and innovation
- **B4:** Target Market and Users (MAX 300 chars) - TAM/SAM, user vs. buyer
- **B5:** Business Model and Revenue (MAX 300 chars) - Revenue model, pricing, unit economics
- **B6:** Traction and Validation (MAX 300 chars) - Quantified evidence only
- **B7:** Team and Resources (MAX 200 chars) - Founders, gaps, advisors

**Maturity Stage Classification:**
- Idea (TRL 1-2)
- Prototype (TRL 3-4)
- Pilot (TRL 5-6)
- Early Commercialization (TRL 7-8)
- Growth (TRL 9)

**Supplementary Notes (MAX 250 chars each):**
- Market Context
- Strategic Importance
- Technology Platform Potential
- Key Dependencies and Risks
- Evidence Quality Assessment

**Outputs:**
- Executive Brief (Markdown + DOCX)
- Maturity stage classification with TRL rating
- Evidence tracking for all major claims
- Red flags identified

**Quality Checks:**
- [ ] All character limits strictly enforced (B1: 150, B2-B6: 300, B7: 200)
- [ ] Problem statement (B2) is solution-neutral (no tech/product mentions)
- [ ] Traction (B6) is fully quantified with numbers
- [ ] Users and buyers (B4) clearly distinguished or noted as same
- [ ] Evidence tracking complete for all sections
- [ ] Maturity stage matches evidence

**Next Step:** Proceed to Step 1 (if using application forms) or Step 2

---

### STEP 1: Application Forms [OPTIONAL] (15-20 min)

**Purpose:** Transform Executive Brief into program-specific standardized application formats

**Prompt Location:** `prompts/step_1_application_forms.md`

**Template Locations:**
- `templates/360SIS_Application_Template.md` (Social impact ventures)
- `templates/CNEN_Application_Template.md` (Research institutions)

**Two Standard Formats:**

**Format 1: 360 SIS Application**
- **Use for:** Social enterprises, impact investing, SDG-focused programs
- **Structure:** 7 sections with Theory of Change framework
- **Maturity Stages:** Discovery â†’ Validation â†’ Preparation â†’ Growth â†’ Scaling â†’ Maturity
- **Sentence Limits:** Project Summary 2-3, all others 3-5 sentences
- **Special Features:** Impact metrics, Theory of Change table, stage justification

**Format 2: CNEN Application**
- **Use for:** Research institutions, tech transfer, academic spin-outs
- **Structure:** 5 sections with TRL emphasis
- **TRL Focus:** Technology Readiness Level 1-9 with justification
- **Sentence Limits:** Executive Summary 2-3, all others 3-5 sentences
- **Special Features:** Scientific impact, IP status, institutional support

**Key Requirements:**
- All content maps from Executive Brief (Step 0)
- Character limits: Summary 500, others 750 chars
- Sentence limits strictly enforced (2-3 or 3-5)
- All tables completed with actual data
- DOCX output for professional submission

**When to Use:**
- Managing cohorts in accelerator/incubator programs
- Submitting to specific program requirements
- Institutional applications (research, grants)

**When to Skip:**
- Ad-hoc evaluations without formal program
- Moving directly to diagnostic assessment
- No standardized application format required

**Next Step:** Proceed to Step 2

---

### STEP 2: 40-Question Diagnostic (30-45 min)

**Purpose:** Comprehensive assessment across Team, Technology, Management, and Commercial dimensions with two-document output

**Prompt Location:** `prompts/step_2_diagnostic_40q.md`

**Template Locations:**
- `templates/40Q_Assessment_Results_Template.md` (Comprehensive document)
- `templates/40Q_Score_Summary_Template.md` (Executive brief)

**Scoring Scale:**
- **5** = Complete - External validation, documented evidence, multiple sources
- **4** = Strong - Some external validation, clear capability, preliminary evidence
- **3** = Adequate - Internal validation only, reasonable assumptions, basic capability
- **2** = Weak - Significant gaps identified, aware but not addressed, concerning
- **1** = Critical Gap - No evidence, major deficiency, not addressed, red flag

**Special Response Types:**
- **INSUFFICIENT DATA** - Application lacks information to score
- **CONTEXTUAL NOTE** - Score needs important qualification
- **YES/NO** - Binary question where score doesn't apply
- **N/A** - Question not relevant to this specific venture

**Dimensions:**
- **Team** (T1-T9): 9 questions - Technical completeness, experience, domain expertise, commitment
- **Technology** (Tech1-Tech11): 11 questions - Innovation, feasibility, IP, scalability, security, QA
- **Management** (M1-M12): 12 questions - Strategy, financial planning, operations, governance
- **Commercial** (C1-C8): 8 questions - Customer validation, market size, business model, revenue validation

**Two-Document Output:**

**Document 1: Assessment Results (Comprehensive)**
- All 40 questions with scores and evidence
- Dimensional analyses with red flags
- Top strengths (scores 4-5)
- Critical gaps (scores 1)
- Major weaknesses (scores 2)
- Questions to Ask Founders (INSUFFICIENT DATA items)
- 5-paragraph narrative assessment
- Recommendation for next steps

**Document 2: Score Summary (Executive Brief)**
- Executive summary (2-3 paragraphs)
- Dimensional scores table
- Top 5 strengths
- Top 5 gaps/concerns
- Red flags summary
- Strategic recommendations (immediate + medium-term)
- Stage appropriateness assessment
- Final recommendation with justification

**Quality Checks:**
- [ ] All 40 questions scored or marked with special response
- [ ] Evidence/gap provided for each score
- [ ] All dimension averages calculated correctly
- [ ] Red flags identified (18 specific red flag patterns)
- [ ] "Questions to Ask Founders" list complete
- [ ] Both documents generated (Results + Summary)
- [ ] Recommendation is specific and justified
- [ ] Stage appropriateness evaluated

**Next Step:** Proceed to Step 3

---

### STEP 3: Market Maturity Assessment (45-60 min)

**Purpose:** Evaluate readiness across all five VIANEO dimensions

**Prompt Location:** `prompts/step_3_market_maturity_29q.md` (or use `docs/VIANEO_Market_Maturity_System_Prompt.md`)

**Scoring Scale:**
- **5** = Absolutely (strong external validation)
- **4** = Almost (good evidence)
- **3** = Likely (basic validation)
- **2** = Maybe not (weak evidence)
- **1** = Don't know (no evidence)

**Question Mapping:**
- **Legitimacy** (2 questions): Q8, Q13
- **Desirability** (12 questions): Q1-4, Q9-10, Q14-16, Q21-22, Q27
- **Acceptability** (6 questions): Q5-7, Q17-19
- **Feasibility** (5 questions): Q11-12, Q24-25, Q28
- **Viability** (4 questions): Q20, Q23, Q26, Q29

**Outputs:**
- 29 individual scores with evidence basis
- 5 dimensional scores
- Overall weighted score
- Pass/Fail against thresholds
- Narrative commentary

**Thresholds:**
- Legitimacy: â‰¥3.0
- Desirability: â‰¥3.5 (highest)
- Acceptability: â‰¥3.0
- Feasibility: â‰¥3.0
- Viability: â‰¥3.0
- **Overall: â‰¥3.2**

**Quality Checks:**
- [ ] All 29 questions scored
- [ ] Confidence level noted per question
- [ ] Dimensional scores calculated correctly
- [ ] Overall weighted score uses correct formula
- [ ] All thresholds checked

**Next Step:** Proceed to Step 4

---

### STEP 4: Legitimacy Deep Dive (20-30 min)

**Purpose:** Detailed validation of problem significance and domain appropriateness

**Prompt Location:** `prompts/step_4_legitimacy_worksheet.md`

**Worksheet Location:** `worksheets/Legitimacy_Analysis_Template.md`

**Components:**
1. **Problem Definition Analysis** (25% of legitimacy score)
   - Solution-neutrality check
   - Measurability and specificity
   - Evidence of problem existence

2. **Problem Significance** (25% of legitimacy score)
   - Magnitude (how many affected)
   - Severity (impact level)
   - Urgency (timeline pressure)
   - Economic impact

3. **Field of Application Analysis** (25% of legitimacy score)
   - Domain specificity and stability
   - Problem-domain fit
   - Alternative domains consideration

4. **Innovator's Approach** (25% of legitimacy score)
   - Unique insight or perspective
   - Domain experience and credibility
   - Approach differentiation

**Outputs:**
- Component scores for each element
- Total legitimacy score (0-5)
- Red flag identification
- Specific recommendations

**Quality Checks:**
- [ ] Problem statement evaluated for solution-neutrality
- [ ] Evidence cited for problem significance
- [ ] Domain fit assessed objectively
- [ ] Team credibility documented

**Next Step:** Proceed to Step 5

---

### STEP 5: Desirability Analysis (30-40 min)

**Purpose:** Identify and structure user segments, needs, and personas

**Prompt Location:** `prompts/step_5_desirability_personas.md`

**Part 1: Requester Segments (3-10 segments)**

For each segment:
- Name (max 60 characters)
- Description (100 words)
- Population size
- Current solution used
- Validation status (# interviewed)

**Part 2: Needs Statements (5-15 distinct needs)**

Requirements:
- Max 60 characters each
- Solution-neutral
- Distinct from other needs
- Action-oriented format: [Verb] + [Object] + [Context]

**Distinctness Test:**
Ask: "Can I satisfy Need A without satisfying Need B?"
- If NO â†’ Consolidate into single need
- If YES â†’ Keep separate

**Part 3: Validation Matrix**

Map which segments have which needs (used for Step 6)

**Part 4: Priority Ranking**

Rank needs by:
1. Criticality (fundamental to segment)
2. Frequency (how often experienced)
3. Dissatisfaction (current solution gaps)

**Optional: Persona Development**

Create 3-5 detailed personas for top segments including:
- Demographics and context
- Current behaviors and pain points
- Decision factors and adoption triggers
- User vs. buyer distinction

**Outputs:**
- Segment definitions with validation status
- Distinct needs list (5-15 items)
- Validation matrix
- Priority ranking
- Personas (optional)

**Quality Checks:**
- [ ] All segments have 60-char names
- [ ] Needs are solution-neutral
- [ ] Distinctness verified for all need pairs
- [ ] Priority ranking based on evidence

**Next Step:** Proceed to Step 6

---

### STEP 6: Needs Qualification Matrix (45 min)

**Purpose:** Create visual HTML heatmap showing importance vs. satisfaction across segments

**Prompt Location:** `prompts/step_6_needs_matrix_html.md`

**Template Location:** `visualizations/needs_matrix_template.html`

**Data Required (from Step 5):**
- List of segments (3-10)
- List of needs (5-15)
- Importance ratings per need-segment combination
- Satisfaction ratings per need-segment combination

**Importance Scale:**
- **4** = Fundamental (segment can't function without)
- **3** = Important (significant impact)
- **2** = Secondary (nice to have)
- **1** = None (not relevant)

**Satisfaction Scale:**
- **4** = Very well satisfied
- **3** = Pretty much satisfied
- **2** = Rather not satisfied
- **1** = Not at all satisfied

**Priority Zones (Visual Coding):**
- ðŸ”´ **Critical**: Fundamental (4) + Not satisfied (1)
- ðŸŸ  **High**: Important (3-4) + Rather not satisfied (1-2)
- ðŸŸ¡ **Medium**: Secondary (2) + Not satisfied (1-2)
- ðŸŸ¢ **Low**: Any need + Well satisfied (3-4)

**Outputs:**
- Interactive HTML matrix file
- Priority targets identified
- Visual heatmap of opportunity areas
- Screenshot for reports

**Quality Checks:**
- [ ] HTML renders correctly in browser
- [ ] All segment-need combinations rated
- [ ] Priority zones color-coded properly
- [ ] Interactive hover effects work
- [ ] Mobile responsive

**Next Step:** Proceed to Step 7

---

### STEP 7: Ecosystem Mapping (30-45 min)

**Purpose:** Map all stakeholders with acceptability ratings and mitigation strategies

**Prompt Location:** `prompts/step_7_ecosystem_mapping.md`

**Template Location:** `worksheets/Ecosystem_Mapping_Template.md`

**Stakeholder Categories:**

1. **Enablers** (Upstream suppliers/partners)
   - What they provide
   - Criticality level
   - Current status
   - Acceptability rating

2. **Partners** (Channels/distribution)
   - Distribution/marketing role
   - Reach and audience
   - Current status
   - Acceptability rating

3. **Clients** (Buyers/payers)
   - Purchasing power
   - Decision process
   - Current vendors
   - Switching costs

4. **End Users** (If different from buyers)
   - Relationship to buyers
   - Influence level
   - Adoption barriers
   - Acceptability rating

5. **Regulators/Influencers**
   - Type and influence scope
   - Current position
   - Engagement strategy
   - Acceptability rating

**Acceptability Ratings:**
- **Favorable**: Supportive, ready to engage
- **Neutral**: Aware but uncommitted
- **Unfavorable**: Resistant or opposed

**Analysis Components:**
- Overall acceptability score (% favorable)
- Risk assessment (unfavorable + critical = high risk)
- Mitigation strategies for resistance
- Relationship dynamics and dependencies

**Outputs:**
- Complete stakeholder table with ratings
- Acceptability score calculation
- Risk assessment by criticality
- Priority actions for engagement

**Quality Checks:**
- [ ] All stakeholder categories covered
- [ ] Acceptability ratings evidence-based
- [ ] Mitigation strategies for unfavorable players
- [ ] Critical dependencies identified

**Next Step:** Proceed to Step 8 (or stop here for Standard path)

---

### STEP 8: Network Visualization (60-90 min)

**Purpose:** Create interactive HTML visualization of complete value network

**Prompt Location:** `prompts/step_8_network_visualization.md`

**Template Location:** `visualizations/network_map_template.html`

**Data Structure (from Step 7):**

```javascript
{
  company: { name, product },
  enablers: [{ name, criticality, acceptability, needs }],
  channels: [{ name, type, acceptability, reach }],
  buyers: [{ name, acceptability, isPriorityTarget, needs }],
  endUsers: [{ name, acceptability, needs }],
  influencers: [{ name, type, acceptability, influence }]
}
```

**Visualization Features:**
- 5-column grid layout (Enablers â†’ Product â†’ Channels â†’ Buyers â†’ Users)
- Color-coded by acceptability (green/yellow/red)
- Priority targets highlighted with animation
- Hover effects for details
- Responsive design
- Summary statistics dashboard

**Outputs:**
- Interactive HTML network map
- Statistics summary (total players, favorable %, priority targets)
- Visual representation of value flow
- Screenshot for executive reports

**Quality Checks:**
- [ ] All players positioned correctly
- [ ] Acceptability colors accurate
- [ ] Priority targets highlighted
- [ ] Statistics calculated correctly
- [ ] Interactive elements functional
- [ ] Professional appearance

**Next Step:** Create final committee report

---

## Quality Control Framework

### Per-Step Validation

After each step, verify:

**Step 0:**
- [ ] Character limits met (250 for problem, 60 for needs/players)
- [ ] Problem statement is solution-neutral
- [ ] Users â‰  Buyers where applicable
- [ ] Evidence gaps explicitly noted

**Step 2:**
- [ ] All 40 questions scored 1-5
- [ ] Evidence cited for every score â‰¥3
- [ ] Dimension averages calculated
- [ ] Red flags identified

**Step 3:**
- [ ] All 29 questions scored 1-5
- [ ] Dimensional mapping correct
- [ ] Weighted overall score uses formula: (LÃ—0.15)+(DÃ—0.25)+(AÃ—0.20)+(FÃ—0.20)+(VÃ—0.20)
- [ ] All thresholds checked

**Step 4:**
- [ ] All 4 components scored
- [ ] Legitimacy total calculated correctly
- [ ] Red flags checked (solution in problem, no evidence, wrong domain)

**Step 5:**
- [ ] 3-10 segments defined
- [ ] 5-15 distinct needs
- [ ] Independence verified for all need pairs
- [ ] Priority ranking evidence-based

**Step 6:**
- [ ] HTML renders in browser
- [ ] All cells have both importance and satisfaction
- [ ] Priority zones color-coded
- [ ] Screenshots captured

**Step 7:**
- [ ] All 5 stakeholder types covered
- [ ] Acceptability ratings for each player
- [ ] Mitigation strategies for unfavorable
- [ ] Overall acceptability calculated

**Step 8:**
- [ ] All players visualized
- [ ] Statistics accurate
- [ ] Interactive features work
- [ ] Professional appearance

---

## Final Output Package

### For Committee Review

**Document Package:**
1. **Executive Summary** (2 pages)
   - Company overview
   - One-line summary
   - Key metrics dashboard
   - Recommendation

2. **Dimensional Scores Table** (1 page)
   - All 5 dimensions with scores
   - Pass/Fail status
   - Overall weighted score
   - Threshold comparison

3. **Visual Outputs**
   - Needs Qualification Matrix (HTML + screenshot)
   - Network Map (HTML + screenshot)

4. **Deep Dive Documents**
   - Complete 40-question diagnostic
   - Complete 29-question market maturity
   - Legitimacy worksheet
   - Ecosystem mapping table

5. **Final Recommendation** (1-2 pages)
   - Go / Conditional / No-Go decision
   - Key conditions if conditional
   - Top 3 questions for discussion
   - Immediate next steps

**Presentation Deck (Optional):**
- Slide 1: Company overview
- Slide 2: Problem and solution
- Slide 3: Market opportunity
- Slide 4: Dimensional scores visualization
- Slide 5: Needs matrix (screenshot)
- Slide 6: Network map (screenshot)
- Slide 7: Key risks and mitigations
- Slide 8: Recommendation and next steps

---

## Common Issues and Solutions

### Character Limit Violations

**Problem:** Field exceeds max characters

**Solutions:**
1. Remove adjectives and adverbs
2. Use active voice instead of passive
3. Combine related concepts
4. Abbreviate where context is clear
5. Focus on core meaning, not elaboration

**Example:**
- Before (68 chars): "Healthcare providers need to easily track patient medication schedules"
- After (47 chars): "Track patient medication schedules easily"

---

### Overlapping/Redundant Needs

**Problem:** Satisfying Need A automatically satisfies Need B

**Test:** "Can I satisfy A without satisfying B, and vice versa?"

**Example:**
- Need A: "Access care remotely"
- Need B: "Reduce travel to clinic"
- **Result:** These overlap - combine to: "Access care without travel"

---

### Missing Evidence

**Problem:** No data available to score question

**Solution:**
1. Score as 1 or 2 (insufficient/weak)
2. Note "Insufficient data: [specific gap]"
3. Flag for follow-up questions
4. Include in final recommendation conditions

---

### High Scores Without Evidence

**Problem:** Evaluator wants to score 4-5 but has no external validation

**Solution:**
1. Default to maximum score of 2-3 without external evidence
2. Add note: "Claim requires validation: [specific evidence needed]"
3. Classify as assumption not fact
4. Flag as key due diligence item

---

### Generic or Solution-Embedded Problem Statements

**Problem:** "Need a mobile app for healthcare scheduling"

**Fixes:**
1. Remove solution: "Need a mobile app" â†’ remove
2. Add measurability: "for healthcare scheduling" â†’ "to reduce appointment no-shows by 30%"
3. Specify population: Add "for rural patients"
4. **Result:** "Rural patients need to reduce appointment no-shows by 30%"

---

## Time Management

### Per-Project Time Budget

**Fast Track** (90 minutes):
- Step 0: 25 min
- Step 2: 35 min
- Step 4: 15 min
- Step 5: 15 min

**Standard** (3-4 hours):
- Step 0: 25 min
- Step 2: 35 min
- Step 3: 50 min
- Step 4: 25 min
- Step 5: 35 min
- Step 6: 30 min
- Step 7: 30 min

**Complete** (5-6 hours):
- Step 0: 25 min
- Step 1: 10 min
- Step 2: 35 min
- Step 3: 50 min
- Step 4: 25 min
- Step 5: 40 min (with personas)
- Step 6: 45 min
- Step 7: 40 min
- Step 8: 75 min
- Report: 30 min

### Cohort Processing

**10 Startups Fast Track:**
- 90 min Ã— 10 = 15 hours
- Spread over 3-4 days
- Select top 5 for deeper evaluation

**Top 5 Standard Evaluation:**
- 4 hours Ã— 5 = 20 hours
- Spread over 1 week
- Select top 2-3 for complete

**Top 3 Complete Assessment:**
- 6 hours Ã— 3 = 18 hours
- Final committee packages
- Executive presentations ready

---

## Scoring Rubrics Reference

### Evidence-Based Scoring (All Steps)

**Score 5 - Exceptional:**
- Multiple external validation sources
- Quantified data supporting claims
- Documented evidence readily available
- Third-party verification possible

**Score 4 - Strong:**
- External validation from credible sources
- Clear evidence with some gaps
- Most claims verifiable
- Strong signals of capability

**Score 3 - Adequate:**
- Basic validation or internal evidence
- Reasonable assumptions based on data
- Meets minimum threshold
- Some external signals

**Score 2 - Weak:**
- Limited validation
- Mostly assumptions
- Aware of gaps but not addressed
- Concerning signals

**Score 1 - Critical Gap:**
- No validation or evidence
- Pure speculation
- Major deficiency
- Red flag territory

---

## Success Metrics

Track these to improve your evaluation process:

**Efficiency Metrics:**
- Time per step decreasing over iterations
- Character limit violations <5%
- 100% evidence citation for scores â‰¥3

**Accuracy Metrics:**
- Compare dimensional scores to 12-month outcomes
- Track prediction accuracy (recommended vs. reality)
- False positive rate (recommended but failed)
- False negative rate (passed but should have been conditional)

**Utility Metrics:**
- Committee finds insights actionable
- Founders find feedback valuable
- Investors use for decision-making
- Accelerators use for milestone tracking

---

## Customization Guide

This system can be adapted for specific contexts:

### Sector-Specific Adaptations

**Healthcare/MedTech:**
- Add regulatory timeline questions
- Weight Acceptability higher (25%)
- Add clinical validation evidence requirements

**FinTech:**
- Add compliance and licensing questions
- Weight Viability higher (25%)
- Add unit economics depth

**B2B SaaS:**
- Add enterprise sales cycle questions
- Focus on customer validation in Desirability
- Add implementation complexity

### Stage-Specific Adaptations

**Pre-Seed:**
- Lower evidence thresholds for scores
- Focus on Legitimacy and Desirability
- Accept more assumptions in Viability

**Seed:**
- Standard thresholds as designed
- Balance across all dimensions
- Require basic customer validation

**Series A+:**
- Raise evidence thresholds
- Require extensive validation
- Weight Viability and Acceptability higher

---

## File Naming Conventions

Use consistent naming for organization:

```
[CompanyName]_[Date]_[StepNumber]_[StepName].[ext]

Examples:
HealthTech_2025-01-15_00_Canvas.md
HealthTech_2025-01-15_02_Diagnostic.md
HealthTech_2025-01-15_03_MarketMaturity.md
HealthTech_2025-01-15_04_Legitimacy.md
HealthTech_2025-01-15_05_Desirability.md
HealthTech_2025-01-15_06_NeedsMatrix.html
HealthTech_2025-01-15_07_Ecosystem.md
HealthTech_2025-01-15_08_NetworkMap.html
HealthTech_2025-01-15_FINAL_Report.pdf
```

---

## Quick Reference Commands

For rapid execution with AI assistant:

```
"Execute VIANEO Step 0 canvas extraction on this document"
"Run 40-question diagnostic with evidence citations"
"Complete 29-question market maturity assessment"
"Generate legitimacy worksheet analysis"
"Extract user segments and needs for desirability"
"Create needs qualification matrix HTML"
"Map ecosystem with acceptability ratings"
"Generate interactive network visualization"
"Compile complete evaluation package"
```

---

## Resources and Templates

All prompts and templates are located in:

**Prompts:** `/prompts/step_[0-8]_*.md`
**Templates:** `/templates/*.md`
**Worksheets:** `/worksheets/*.md`
**Visualizations:** `/visualizations/*.html`
**Examples:** `/examples/*_Complete_Evaluation.md`

---

## Support and Documentation

**Core Documentation:**
- This complete skill guide
- Individual step prompts (detailed instructions)
- Quick Reference Card (one-page reminder)
- System Overview (how components fit together)

**For Questions:**
1. Check relevant step prompt file
2. Review example evaluations
3. Consult Quick Reference Card
4. Review scoring rubrics above

---

## Version Information

**System Version:** 2.0 (Complete 8-Step System)
**Framework:** VIANEO Business Model Evaluation Methodology
**Last Updated:** 2025-01-15
**Author:** Claude Code Implementation

---

## Next Steps

1. **Review the Quick Reference Card** at `docs/VIANEO_Quick_Reference_Card.md`
2. **Choose your execution path** (Fast Track / Standard / Complete)
3. **Gather startup materials** (application, pitch deck, research)
4. **Start with Step 0** using `prompts/step_0_canvas_extraction.md`
5. **Work sequentially** through your chosen path
6. **Generate final report** using `templates/Committee_Report_Template.md`

**Ready to begin your first evaluation!**
