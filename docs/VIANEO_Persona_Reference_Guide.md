# Vianeo Persona Reference Guide

## Purpose of This Guide

This comprehensive reference provides detailed examples, scoring rubrics, interview guidelines, and quality standards for creating exceptional Vianeo personas that validate the Desirability dimension (25% of total evaluation score).

---

## Table of Contents

1. [Understanding Personas in Vianeo](#understanding-personas-in-vianeo)
2. [The Four-Layer Persona Structure](#the-four-layer-persona-structure)
3. [Complete Example Persona](#complete-example-persona)
4. [Scoring Rubric](#scoring-rubric-for-persona-quality)
5. [Interview Guidelines](#interview-guidelines)
6. [Common Pitfalls and Solutions](#common-pitfalls-and-solutions)
7. [Evidence Documentation](#evidence-documentation-template)
8. [Quality Check Questions](#quality-check-questions)

---

## Understanding Personas in Vianeo

### Role in Business Model Evaluation

Personas serve multiple critical functions in the Vianeo framework:

1. **Validate Problem Statement:** Personas demonstrate that the problem defined in Legitimacy affects real people with actual needs
2. **Document User Needs:** Personas provide evidence for Desirability assessment (25% of score)
3. **Inform Ecosystem Mapping:** Personas identify requester segments for Acceptability analysis
4. **Drive Feature Prioritization:** Personas guide Feasibility evaluation of functionality
5. **Support Revenue Model:** Personas validate Viability assumptions about willingness to pay

### Connection to Other Dimensions

**Legitimacy (15%):**
- Personas validate that problem statement addresses real user needs
- Evidence from personas confirms problem significance
- User quotes support problem discovery narrative

**Acceptability (20%):**
- Personas map to requester segments in ecosystem
- User roles inform stakeholder influence analysis
- Persona needs drive value network positioning

**Feasibility (20%):**
- Persona tasks define required functionalities
- Current solutions inform technical requirements
- User workflows shape implementation priorities

**Viability (20%):**
- Persona pain points validate value proposition
- Current solution costs inform pricing strategy
- Willingness to pay evidence from interviews

---

## The Four-Layer Persona Structure

### Layer 1: Requester (Who They Are)

**Purpose:** Establish the human behind the need. This goes beyond demographics to understand their context, drivers, and core values that influence decisions.

**What to Include:**
- **First name:** Single name for personalization without formality
- **Age:** Specific number showing life stage context
- **Life/Motivations:** Career path, current situation, what drives their choices
- **Personality/Values:** Character traits that affect how they solve problems

**Why This Matters:** Understanding who they are helps predict how they'll evaluate solutions, what messaging will resonate, and what objections they'll have.

### Layer 2: Field of Application (Their World)

**Purpose:** Capture their mental model, observations, behaviors, and social context. Shows you understand not just who they are but how they experience the problem.

**What to Include:**
- **Thinks/Feels:** Internal emotional state, worries, hopes about the problem
- **Observes:** External patterns they notice in their environment
- **Does:** Actual behaviors and current coping mechanisms
- **Others Say:** Social feedback and reputation context

**Why This Matters:** This layer reveals the gap between what they know (observes), what they feel (thinks/feels), and what they do (actions), which is where innovation opportunities live.

### Layer 3: Activities and Challenges (What They Do and Struggle With)

**Purpose:** Document actual tasks, specific pain points, and concrete hopes. This is where validated needs become clear and measurable.

**What to Include:**
- **Tasks/Activities:** Regular responsibilities and workflows (4-6 bullets, max 60 chars each)
- **Pains/Lacks:** Specific frustrations and gaps (4-6 bullets, max 60 chars each)
- **Expectations/Hopes:** Desired outcomes and improvements (4-6 bullets, max 60 chars each)

**Why This Matters:** This layer provides the concrete, measurable needs that drive feature development and prioritization decisions.

### Layer 4: Current Solutions (Their Present Reality)

**Purpose:** Show you understand their current workarounds, why those fail, and the gaps your solution could fill.

**What to Include:**
- Specific tools and products they currently use (with names)
- Why these solutions are inadequate
- What gaps remain that create opportunity

**Why This Matters:** Understanding why current solutions fail is as important as understanding the need itself. It reveals barriers to adoption and switching costs.

---

## Complete Example Persona

### **Persona 1: Independent Grant Consultant**

**[VALIDATION STATUS BADGE]**

| Validation Status |
|-------------------|
| **✓ VALIDATED (8 interviews conducted October-November 2024 via partnership relationships)** |

*Badge Styling: Background #E8F4EA, Text #2D7A3E, 24pt bold, centered*

---

### **Requester**

**First name:**

Marcus

**Age:**

42

**Life/Motivations:**

Runs a solo grant writing consultancy serving 8-12 nonprofit clients simultaneously, working from his home office in Portland after leaving a foundation job five years ago. He's driven by the desire to help mission-driven organizations succeed while maintaining the flexibility to control his own schedule and client mix. His business depends entirely on his ability to deliver high-quality proposals quickly, and he's constantly managing the tension between taking on more clients and maintaining excellence.

**Personality/Values:**

Deeply conscientious and detail-oriented with a perfectionist streak that sometimes slows him down but ensures exceptional client outcomes. Values his reputation above everything else since his entire business model depends on word-of-mouth referrals and repeat clients. Makes decisions methodically, researching tools thoroughly before committing, because a bad tool choice could derail multiple client projects simultaneously.

---

### **Field of Application**

**Thinks/Feels:**

Constantly worried about becoming the bottleneck for his clients' funding opportunities and fears that one missed deadline could destroy years of relationship-building. Feels torn between taking on new clients (more revenue) and maintaining the quality that built his reputation. Anxious about younger consultants using AI tools to undercut his rates while he's still drafting everything manually.

**Observes:**

Watches his nonprofit clients struggle with tighter budgets while foundation requirements become more complex every year. Notices colleagues burning out from 60+ hour weeks during peak grant seasons, and sees ChatGPT-generated proposals getting rejected for being too generic. Witnesses larger consulting firms building internal AI tools while he lacks the resources to develop anything comparable.

**Does:**

Works 50-60 hours weekly during grant seasons, typically juggling 3-4 proposals at different stages across multiple clients. Maintains detailed spreadsheets tracking every deadline, requirement, and funder relationship. Spends Sunday evenings reviewing the week ahead and redistributing workload when conflicts emerge. Manually templates sections from past successful grants but customizes everything extensively.

**Others Say:**

Clients describe him as "worth every penny" and "the person who actually reads the RFP thoroughly," while colleagues admire his success but warn about his unsustainable workload. His family gently pushes him to hire help or scale back, noting he hasn't taken a real vacation in two years.

---

### **Activities and Challenges**

#### **Tasks/Activities**

● Manage 8-12 concurrent client grant projects
● Research 15-20 RFPs monthly for client fit
● Draft 40-100 page proposals with budgets
● Gather client data and program outcomes
● Track revisions across multiple stakeholders
● Maintain funder relationship intelligence

*Character counts: 47, 43, 41, 40, 45, 42 (all under 60) ✓*

#### **Pains/Lacks**

● 12-15 hours per proposal on repetitive sections
● No system to track what proposal language works
● Missing project management for consultant workflows
● Cannot scale beyond 12 clients without burnout
● Lacking intelligence on competitor AI tool usage
● Cannot justify premium rates vs. "free" ChatGPT

*Character counts: 48, 49, 52, 49, 48, 51 (all under 60) ✓*

#### **Expectations/Hopes**

● Reduce drafting time 40-50% while maintaining quality
● Scale from 12 to 18-20 clients without weekends
● Build reusable knowledge base by funder type
● Tool costs under $200/month with clear ROI
● Access funder intelligence beyond just writing
● Maintain competitive edge over generic AI users

*Character counts: 56, 50, 48, 44, 48, 49 (all under 60) ✓*

---

### **Current Solutions**

Currently uses Microsoft Word with manually maintained template library, Asana for deadline tracking, and Google Sheets for client project status, which requires constant context-switching and offers no AI assistance. Experimented with ChatGPT Plus ($20/month) but found outputs too generic and obviously AI-generated, requiring extensive rewriting that eliminated time savings. Instrumentl subscription ($179/month) provides funder research but no writing assistance, creating a fragmented workflow that still demands 50+ hours weekly during peak seasons.

---

## Scoring Rubric for Persona Quality

### Overall Persona Scoring (1-5 Scale)

Use this rubric to evaluate overall persona quality for the Desirability dimension:

**5 - Exceptional Personas (10+ interviews each)**
- Based on 10+ validated interviews per persona
- Include direct quotes and specific behavioral observations
- Each persona is clearly distinct with non-overlapping needs
- Current solutions are specifically named with detailed gap analysis
- Pain points are quantified (time lost, money spent, errors made)
- Shows deep understanding of user context and decision factors
- Multiple sources of validation (interviews, observations, usage data)

**4 - Strong Personas (5-10 interviews each)**
- Based on 5-10 interviews per persona
- Good behavioral detail with solid validation
- Personas are distinct though some minor overlap possible
- Current solutions identified with basic gap analysis
- Most pain points are specific and measurable
- Clear understanding of user workflows and constraints
- Some quantification of impact and costs

**3 - Adequate Personas (3-5 interviews each)**
- Based on 3-5 interviews per persona (minimum acceptable)
- Basic behavioral information provided
- Personas are somewhat distinct
- Current solutions mentioned but not deeply analyzed
- Pain points are identified but not all are specific
- General understanding of user needs
- Limited quantification

**2 - Weak Personas (1-2 interviews only)**
- Based on 1-2 interviews or mostly secondary research
- Limited behavioral detail, mostly demographics
- Significant overlap between personas
- Current solutions vaguely mentioned
- Pain points are generic or assumed
- Superficial understanding of user context
- Heavy reliance on assumptions

**1 - Critical Gap (No validation)**
- No interview validation conducted
- Generic or hypothetical personas
- No clear distinction between personas
- No current solution analysis
- Assumed needs without evidence
- Would not support funding decision
- Requires complete rework

### Component-Level Scoring

**Requester Section Quality:**
- **5:** Vivid, specific details with clear career narrative and specific numbers
- **3:** Basic demographic info with some context
- **1:** Generic age range and vague professional description

**Field of Application Quality:**
- **5:** Each subsection reveals distinct insights with specific examples
- **3:** Provides general observations without deep specifics
- **1:** Generic statements that could apply to anyone

**Activities/Challenges Quality:**
- **5:** All bullets under 60 chars, quantified, specific, measurable
- **3:** Most bullets specific but some may be generic
- **1:** Vague bullets over character limit with no quantification

**Current Solutions Quality:**
- **5:** Names 3+ specific tools with pricing, explains gaps in detail
- **3:** Mentions 1-2 tools with basic gap description
- **1:** Vague "various tools" with no analysis

---

## Interview Guidelines

### Pre-Interview Preparation

**Identify Target Segments:**
1. Define 3-5 distinct user/customer segments
2. For each segment, identify 5-10 potential interview candidates
3. Prioritize candidates who represent "extreme users" or "lead users"
4. Create interview guide with core questions (see below)

**Recruit Participants:**
- Use existing network and customer relationships
- Offer appropriate incentives (gift cards, early access, etc.)
- Be clear about time commitment (30-60 minutes)
- Schedule interviews within 2-3 week window for consistency

### Core Interview Questions

**Understanding Their World:**
1. "Walk me through your typical day/week dealing with [problem area]"
2. "What's the most frustrating part of [current process]?"
3. "How much time/money/effort does this problem cost you?"
4. "What have you tried to solve this? Why didn't it work?"
5. "Show me how you currently handle [specific task]" (if possible)

**Understanding Their Needs:**
1. "If you had a magic wand, what would you fix first?"
2. "What would success look like for you?"
3. "What's preventing you from achieving that today?"
4. "Who else is affected when this problem occurs?"
5. "What would make this worth paying for?"

**Understanding Their Context:**
1. "Who influences your decisions about [solution area]?"
2. "What would make you switch from your current solution?"
3. "What would make you NOT adopt a new solution?"
4. "How do you currently measure success?"
5. "What questions should I have asked that I didn't?"

### During the Interview

**Best Practices:**
- Record with permission (for quote extraction and analysis)
- Take notes even while recording
- Ask "why" at least 3 times for each answer
- Look for specific stories and examples
- Note exact phrases and terminology they use
- Observe their environment if possible
- Ask to see their current tools/workflows

**Red Flags:**
- Generic answers without specifics
- Focusing on solutions rather than problems
- Hypothetical answers ("I would probably...")
- Contradictory statements about importance vs. behavior

### Post-Interview Analysis

**Extract Key Data:**
1. Direct quotes about pain points
2. Specific behaviors and workflows described
3. Current tools mentioned with pros/cons
4. Quantified impacts (time, cost, frequency)
5. Decision factors and buying criteria

**Identify Patterns:**
- Which needs appear across multiple interviews?
- What pain points are most intense/frequent?
- Which current solutions are most common?
- What unexpected insights emerged?

**Determine Segmentation:**
- Do distinct groups emerge with different needs?
- Can you cluster interviews into 3-5 personas?
- What makes each group unique?

---

## Common Pitfalls and Solutions

### Pitfall 1: The Generic Professional

**Problem:** Creating personas that are too broad and could describe almost anyone.

**Example of Generic Persona:**
"John is a 25-45 year old professional who wants to be more productive and have better tools for his work. He's busy and values his time."

**Why This Fails:**
- Age range instead of specific age
- "Professional" could be anyone
- "Better tools" is solution-focused, not need-focused
- No specific behaviors or context
- Could apply to millions of people

**Solution:**
"Marcus, 42, runs a solo grant writing consultancy serving 8-12 nonprofit clients simultaneously, working from his home office in Portland after leaving a foundation job five years ago. Works 50-60 hours weekly during grant seasons, maintaining detailed spreadsheets tracking every deadline, requirement, and funder relationship."

**Why This Works:**
- Specific age showing life stage
- Precise role and business model
- Numbers that show scale (8-12 clients, 50-60 hours)
- Geographic context (Portland, home office)
- Specific behaviors (spreadsheets, tracking)
- Career history providing credibility

### Pitfall 2: Solution-First Thinking

**Problem:** Embedding your solution into their needs rather than documenting actual problems.

**Wrong Approach:**
"Sarah needs our AI-powered analytics dashboard to manage her projects better."

**Why This Fails:**
- Assumes your solution is the answer
- Doesn't explain what she actually struggles with
- No evidence that AI or dashboards are right approach
- Doesn't show what she currently does

**Solution:**
"Sarah needs to understand project profitability in real-time to make resource allocation decisions, currently impossible with her fragmented spreadsheet system that requires 10+ hours weekly to manually consolidate data from five different sources."

**Why This Works:**
- Describes the actual need (real-time profitability visibility)
- Explains why it matters (resource decisions)
- Shows current state (fragmented spreadsheets)
- Quantifies the pain (10+ hours weekly)
- Doesn't prescribe the solution

### Pitfall 3: Overlapping Personas

**Problem:** Creating multiple personas that essentially have the same needs with different job titles.

**Example of Overlapping Personas:**
- Persona A: "Startup founder needing project management tools"
- Persona B: "Small business owner needing project management tools"

**Why This Fails:**
- Both need "project management tools" generically
- No clear distinction in actual needs
- Waste of research resources
- Confuses prioritization decisions

**Solution:**
Either combine them into one persona OR find what makes them truly distinct:
- Persona A: "Early-stage founder managing technical team sprint across multiple product features" (needs: technical project management, development workflow integration)
- Persona B: "Service business owner coordinating client delivery across field teams" (needs: client communication, scheduling, resource allocation)

**Why This Works:**
- Different contexts (product development vs. client delivery)
- Different workflows (sprint management vs. field coordination)
- Different needs (technical integration vs. client communication)
- Different current solutions would be in use

### Pitfall 4: Character Limit Violations

**Problem:** Bullet points exceed 60 characters, breaking platform compatibility.

**Wrong Examples:**
- "Spending significant time on repetitive proposal sections that require extensive customization" (94 chars) ✗
- "There is currently no adequate system available to track which proposal language is most effective" (99 chars) ✗

**Solution Process:**
1. **Identify the core meaning:** What's the actual point?
2. **Remove unnecessary words:** Cut adjectives and qualifiers
3. **Use numbers instead of words:** "12-15 hours" vs. "significant time"
4. **Front-load key info:** Start with the metric or outcome
5. **Abbreviate universally understood terms:** "RFPs" vs. "requests for proposals"

**Correct Examples:**
- "12-15 hours per proposal on repetitive sections" (48 chars) ✓
- "No system to track proposal language effectiveness" (51 chars) ✓

### Pitfall 5: Missing Current Solutions Analysis

**Problem:** Not documenting what users actually do today and why it fails.

**Wrong Approach:**
"Uses various tools but they don't work well together."

**Why This Fails:**
- "Various tools" is too vague
- "Don't work well" doesn't explain the actual problem
- No insight into why they chose those tools
- No understanding of switching costs

**Solution:**
"Currently uses Microsoft Word with manually maintained template library, Asana for deadline tracking, and Google Sheets for client project status, which requires constant context-switching and offers no AI assistance. Experimented with ChatGPT Plus ($20/month) but found outputs too generic and obviously AI-generated, requiring extensive rewriting that eliminated time savings."

**Why This Works:**
- Names specific tools (Word, Asana, Sheets, ChatGPT Plus)
- Explains why fragmented (context-switching)
- Shows what's missing (AI assistance)
- Reveals they've tried alternatives (ChatGPT)
- Explains why alternative failed (too generic)
- Includes pricing context ($20/month)

---

## Evidence Documentation Template

### For Each Persona, Document:

**Persona Name:** [Role/Title]

**Interview Count:** [Specific number]

**Interview Details:**
- Participant 1: [Role], [Organization Type], [Date], [Duration]
- Participant 2: [Role], [Organization Type], [Date], [Duration]
- Participant 3: [Role], [Organization Type], [Date], [Duration]
- [Continue for all interviews]

**Key Quotes:**
- "[Actual quote about main pain point]" - Participant [N], [Date]
- "[Actual quote about current solution]" - Participant [N], [Date]
- "[Actual quote about desired outcome]" - Participant [N], [Date]

**Behavioral Observations:**
- [Specific behavior witnessed or described]
- [Pattern noticed across multiple interviews]
- [Unexpected finding or insight]

**Current Solution Analysis:**
- **Primary Tool:** [Specific product/service]
  - **Why chosen:** [Reason for adoption]
  - **Why it fails:** [Specific gaps or limitations]
  - **Switching barriers:** [What prevents change]

**Quantified Impacts:**
- Time costs: [Hours per week/month]
- Financial costs: [Dollar amounts for tools, labor, missed opportunities]
- Error rates: [Frequency of mistakes or rework]
- Opportunity costs: [What they can't do because of current limitations]

### Validation Tracking Table

| Persona | Target Interviews | Completed | Date Range | Status | Gaps |
|---------|------------------|-----------|------------|--------|------|
| Grant Consultant | 5 | 8 | Oct-Nov 2024 | Validated | None |
| Nonprofit Director | 5 | 3 | Oct 2024 | Partial | Need 2-3 more |
| Foundation Program Officer | 5 | 0 | Not started | Needs | Need 5-7 |

---

## Quality Check Questions

Before finalizing personas, answer these questions:

### Evidence Quality

1. **How many formal interviews were conducted per persona?**
   - 5+: Strong validation
   - 3-4: Adequate (minimum acceptable)
   - 1-2: Weak (needs more)
   - 0: Invalid (must interview)

2. **Can you cite specific quotes for main pain points?**
   - If no: Interview more people

3. **Do you have quantified data on time/cost impacts?**
   - If no: Follow up with participants for metrics

### Content Quality

4. **Could a salesperson use this persona to identify prospects?**
   - Test: Can they recognize this person in real life?
   - If no: Add more specific details

5. **Could a designer use this persona to make feature decisions?**
   - Test: Are needs specific enough to prioritize?
   - If no: Be more concrete about tasks and pains

6. **Could marketing write copy that speaks to this persona?**
   - Test: Do you know what messaging will resonate?
   - If no: Strengthen "Thinks/Feels" and "Others Say"

7. **Could product prioritize features based on these needs?**
   - Test: Are pains quantified and ranked?
   - If no: Get more data on severity and frequency

### Distinctiveness

8. **Could you satisfy one persona's needs without satisfying another's?**
   - If no: Personas overlap too much, combine or differentiate

9. **Do personas represent different contexts, not just different titles?**
   - Test: Different workflows, different tools, different constraints?
   - If no: You may only have one persona with different names

10. **Would each persona evaluate your solution differently?**
    - Test: Different decision factors, different objections?
    - If no: Personas aren't distinct enough

### Format Compliance

11. **Are all bullet points under 60 characters?**
    - Check every single one with character counter
    - If no: Edit ruthlessly (see Pitfall 4 solutions)

12. **Are all paragraph sections exactly 2-3 sentences?**
    - Count sentences in each field
    - If no: Add or combine sentences to meet requirement

13. **Are current solutions specifically named with tools and prices?**
    - Check for "various tools" or other vague language
    - If no: Follow up with participants for specifics

### Committee Readiness

14. **Would this document support a funding decision?**
    - Test: Does it prove market need exists?
    - If no: Strengthen evidence and specifics

15. **Does validation level match badge color?**
    - Green: 5+ interviews
    - Orange: 1-4 interviews or beta users
    - Red: 0 interviews
    - If no: Update badge or conduct more interviews

---

## Final Quality Standards

### Minimum Acceptable Quality (Score of 3)

To achieve a minimum passing score for Desirability assessment:

- ✓ Minimum 3 interviews per persona
- ✓ Each persona is somewhat distinct
- ✓ All required sections completed
- ✓ Most bullets under 60 characters
- ✓ Current solutions mentioned (even if not detailed)
- ✓ Basic pain points identified
- ✓ Formatting requirements met

### Strong Quality (Score of 4)

To achieve strong validation for Desirability:

- ✓ 5-10 interviews per persona
- ✓ Clear distinction between personas
- ✓ All bullets under 60 characters
- ✓ Current solutions named with basic gap analysis
- ✓ Pain points specific and many quantified
- ✓ Direct quotes available
- ✓ Professional formatting

### Exceptional Quality (Score of 5)

To achieve exceptional validation for Desirability:

- ✓ 10+ interviews per persona
- ✓ Each persona completely unique with non-overlapping needs
- ✓ All bullets under 60 characters and highly specific
- ✓ Current solutions detailed with pricing and gaps
- ✓ All pain points quantified (time, cost, frequency)
- ✓ Multiple direct quotes integrated
- ✓ Behavioral observations documented
- ✓ Professional formatting with excellent writing

---

**This reference guide should be used in conjunction with:**
- **SKILL.md:** Master overview of persona skill
- **PERSONA_GENERATION_PROMPT.md:** Exact template for creating personas

**Version:** 1.0
**Last Updated:** November 2025
**Part of:** Vianeo Business Model Evaluation Playbook
