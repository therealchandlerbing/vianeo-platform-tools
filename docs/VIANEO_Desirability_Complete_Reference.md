# Vianeo Desirability: Needs/Requesters Reference Document
## Complete Analysis Framework and Best Practices

---

## DOCUMENT PURPOSE

This reference provides comprehensive guidance for conducting Vianeo Desirability: Needs/Requesters analysis. Use this to understand:

- **What** each component means and why it matters
- **How** to execute quality analysis with examples
- **When** to use customer validation vs. secondary research
- **Common pitfalls** and how to avoid them
- **Quality standards** for evidence and validation

**Companion documents:**
- **QUICK START:** Quick generation instructions (`VIANEO_Desirability_Quick_Start.md`)
- **EXECUTION GUIDE:** Step-by-step process (`prompts/step_5_needs_requesters.md`)
- **FORMATTING GUIDE:** Visual styling for Word documents (`VIANEO_Document_Formatting_Guide.md`)

---

## TABLE OF CONTENTS

1. [Framework Overview](#framework-overview)
2. [The Four-Document Package](#the-four-document-package)
3. [Component-by-Component Guidance](#component-guidance)
4. [Evidence and Validation Standards](#evidence-standards)
5. [Quality Assurance Checklist](#quality-assurance)
6. [Common Patterns and Pitfalls](#patterns-and-pitfalls)
7. [Integration with Vianeo Framework](#vianeo-integration)

---

## FRAMEWORK OVERVIEW

### What Desirability Assesses (25% of Total Vianeo Score)

**Core Question:** Do specific people need your specific solution?

**Three sub-questions:**
1. **WHO** needs it? (Requesters/customers with validated needs)
2. **WHAT** do they need? (Tasks, pains, expectations they're trying to address)
3. **WHY** insufficient now? (Gaps in existing solutions that create opportunity)

### Why Desirability Matters

**Legitimacy** validates a real problem exists. **Desirability** validates specific segments need your specific approach.

You can have:
- ✓ Legitimate problem (poverty exists)
- ✗ Undesirable solution (people won't use/pay for your product)

**Common failure pattern:** Brilliant technology seeking market vs. market-driven innovation solving validated customer pain.

**This framework prevents that** by forcing honest assessment of validation status before significant investment.

---

## THE FOUR-DOCUMENT PACKAGE

### Package Overview

The Desirability analysis produces four complementary outputs, each serving different audiences and purposes.

### Document 1: Markdown Analysis File

**Purpose:** Master document containing complete analysis

**Format:** Markdown (.md file)

**Audience:**
- Internal team (primary users)
- Collaborators providing feedback
- Version control/iterative refinement

**Use cases:**
- Working document during analysis
- Sharing for team review and input
- Source for generating other formats
- Version tracking and comparison

**Key characteristics:**
- Complete and comprehensive
- Easy to edit and refine
- Version-controllable (Git, etc.)
- Convertible to other formats

**Length:** 15-25 pages (markdown)

---

### Document 2: DOCX Part 1 - Core Analysis

**Purpose:** Professional stakeholder summary

**Format:** Formatted Word document

**Audience:**
- Executive team
- Investors and funders
- Committee members
- Strategic partners
- Board of directors

**Use cases:**
- Investment committee meetings
- Board presentations
- Funding proposal appendix
- Partner due diligence
- Executive briefings

**Content:**
- INPUTS USED
- REQUESTERS TABLE
- NEEDS ANALYSIS
- EXISTING SOLUTIONS

**Key characteristics:**
- Clean and professional
- Scannable with tables/bullets
- Essential data without strategic depth
- Print-ready for meetings

**Length:** 4-6 pages

---

### Document 3: DOCX Part 2 - Strategic Analysis & Recommendations

**Purpose:** Internal planning and decision-making

**Format:** Formatted Word document

**Audience:**
- Internal core team
- Leadership making investment decisions
- Board members needing strategic guidance
- Major investors doing deep due diligence

**Use cases:**
- Internal planning sessions
- Go/no-go investment decisions
- Strategic partner negotiations (transparency about validation)
- Board strategy discussions

**Content:**
- EVIDENCE REQUIREMENTS & VALIDATION STATUS
- REQUESTERS RELIABILITY ASSESSMENT
- INTEGRATION WITH BUSINESS MODEL
- COMPETITIVE POSITIONING INSIGHTS
- RECOMMENDATIONS FOR IMMEDIATE ACTION
- EVIDENCE-BASED VALIDATION CHECKLIST
- CONCLUSION: PATH FORWARD

**Key characteristics:**
- Honest about validation gaps
- Actionable recommendations with metrics
- Clear risk assessment
- Decision-ready with explicit recommendation

**Length:** 8-12 pages

---

### Document 4: DOCX Part 3 - Customer Discovery Interview Guide

**Purpose:** Practical field tool for interviews

**Format:** Formatted Word document (optimized for field use)

**Audience:**
- Team members conducting interviews
- Sales/BD transitioning to commercial discussions
- External consultants validating market
- Students/interns supporting research

**Use cases:**
- Conducting field interviews (print and bring)
- Training team on interview methodology
- Standardizing process across interviewers
- Documenting methodology for stakeholders

**Content:**
- INTERVIEW STRUCTURE (5 phases, 45-60 minutes)
- KEY INSIGHTS TO CAPTURE
- INTERVIEW BEST PRACTICES
- COMMON PITFALLS TO AVOID
- TARGET INTERVIEW SEGMENTS

**Key characteristics:**
- Field-usable and portable
- Question formatting for easy reference
- Clear timing markers
- Works as standalone document

**Length:** 5-7 pages

---

## COMPONENT GUIDANCE

### Section 1: INPUTS USED

**Purpose:** Document what data informed this analysis

**Quality standard:** Be specific and honest

**What to include:**
- Where problem statement originated
- Status of business model canvas
- Interview data: count, segments, format
- Secondary research sources
- What's validated vs. assumed

**Strong example:**
```
Interview/Research Data Status:
23 customer discovery interviews completed across 5 segments (8 research labs,
7 manufacturers, 5 strategic sector buyers, 3 3D printing providers). Average
interview length 52 minutes. Transcripts available. Market sizing from USGS
Rare Earth Elements report (2024) and Brazil trade statistics (MDIC 2023-2024).
```

**Weak but honest example:**
```
Interview/Research Data Status:
No direct customer interviews conducted. Analysis based on secondary research,
market analysis, and team's institutional knowledge. All requesters require
validation through primary research.
```

**Why "weak but honest" is valuable:** It identifies exactly what you need to do next. Don't hide gaps.

**Common mistakes:**
- ❌ Vague: "Some research was conducted"
- ❌ Exaggerated: Calling 2 informal chats "extensive customer validation"
- ❌ Absent: Not documenting what data you used

---

### Section 2: REQUESTERS TABLE

**Purpose:** Identify who needs your solution and validation status

**Structure:** Table with 3 columns

| Requester Role | Description | Reliability |

**Quality standard:** 6-10 distinct requester types

#### Column 1: Requester Role

**Guidelines:**
- Be specific: "Adult children managing early dementia" not "caregivers"
- Professional titles: "Permanent Magnet Manufacturers" not "magnet users"
- Distinguish users from buyers when different
- 3-6 words maximum

**Examples:**
- ✓ "Wind Turbine Component Suppliers"
- ✓ "Hospital Facilities Administrators"
- ✓ "3D Printing Service Providers"
- ❌ "People who need magnets"
- ❌ "Various customers"

#### Column 2: Description (2-4 sentences)

**Strong descriptions include:**
1. **Who they are** - role, context, scale
2. **Why they matter** - relationship to your solution
3. **Current situation** - what they do now, constraints
4. **Specifics** - company size, sector, geography if relevant

**Poor example:**
"People who need magnets for various industrial uses."

**Strong example:**
"Companies producing finished NdFeB magnets for industrial applications. Currently import raw powders from China/Japan. Serve as critical intermediary between raw materials and end-use sectors. Scale: small to medium Brazilian manufacturers facing supply chain vulnerability."

**What makes it strong:**
- Specific role and industry
- Current behavior documented
- Scale specified
- Pain point mentioned

#### Column 3: Reliability Rating

**Four-tier system:**

| Rating | Meaning | When to Use |
|--------|---------|-------------|
| **More than 5 interviewed** | Strong evidence | 6+ interviews with this profile |
| **Less than 5 interviewed [validate with interviews]** | Preliminary validation | 1-5 interviews, need more |
| **Not yet interviewed [validate with interviews]** | Hypothesis only | Logic/research but no direct contact |
| **Unspecified [validate with interviews]** | No data | Unknown validation status |

**Critical rule:** Be ruthlessly honest. Fabricating validation creates false confidence.

**Common pitfalls:**

**Pitfall 1: Generic or overlapping requesters**

❌ Poor:
- "Small businesses"
- "Medium businesses"
- "Large businesses"

These aren't distinct unless needs differ substantially.

✓ Better: Segment by **need difference**, not demographic difference
- "R&D labs needing customized specifications"
- "Manufacturers needing consistent volume supply"
- "Strategic sectors needing domestic sourcing"

**Pitfall 2: Confusing users with buyers**

❌ Single requester: "Hospital administrators"

✓ Two requesters:
- "Hospital facilities administrators" (buyers, decision-makers)
- "Clinical staff" (users, daily interaction)

**Why this matters:** Users and buyers often have different needs. Users care about usability; buyers care about ROI.

**Pitfall 3: Treating hypothesis as validated**

❌ "Less than 5 interviewed" (when you interviewed zero)
✓ "Not yet interviewed [validate with interviews]"

**Rule:** If you haven't talked to them directly, it's "Not yet interviewed"

---

### Section 3: NEEDS ANALYSIS (10 needs total)

**Purpose:** Document what requesters need to accomplish, eliminate, or achieve

**Structure:** Three categories with ~3-4 needs each

#### Framework: Tasks / Pains / Expectations

**TASKS** = Jobs to be done
- Activities they're trying to complete
- Goals they're working toward
- What they must accomplish

**Examples:**
- "Source customized NdFeB powders domestically"
- "Validate magnetic properties for applications"
- "Scale production with consistent quality"

**PAINS** = Problems to eliminate
- Frustrations, obstacles, risks
- What keeps them up at night
- Barriers blocking progress

**Examples:**
- "Eliminate dependency on Chinese imports"
- "Reduce supply chain vulnerability to barriers"
- "Overcome lack of nanostructured sources"

**EXPECTATIONS** = Desired outcomes
- Success criteria
- Desired state they want to reach
- What gives confidence/satisfaction

**Examples:**
- "Access cost-competitive domestic materials"
- "Achieve technical sovereignty in sectors"
- "Enable 3D printing with spherical powders"

#### Quality Standards

**1. Character limit: 60 characters maximum**

Non-negotiable. Forces clarity.

**Techniques:**
- Start with strong verb: "Maintain" not "Need to maintain"
- Cut adjectives: "Track performance" not "Track cognitive performance changes over extended time"
- Remove filler: "Access tools" not "Access affordable clinical-grade assessment tools"
- Use abbreviations if universal: "NdFeB" not "Neodymium-Iron-Boron"

**Character count examples:**
```
✓ 57 chars: "Access cost-competitive domestic raw materials"
✓ 59 chars: "Eliminate dependency on Chinese/Japanese imports"
✓ 60 chars: "Enable 3D printing applications with spherical powders"
❌ 72 chars: "Access affordable cost-competitive domestic raw materials supply"
```

**2. Each need must be distinct**

**Test:** "Could I satisfy one need without satisfying another?"

❌ **Overlapping needs:**
- "Maintain cognitive health"
- "Keep brain sharp"
- "Prevent decline"

These are the same need worded differently.

✓ **Distinct needs:**
- "Track cognitive performance objectively" (measurement)
- "Practice evidence-based brain training" (intervention)
- "Identify early decline signs" (detection)

These are different needs, potentially requiring different solutions.

**3. No embedded solutions**

❌ "Need mobile app to track brain health"

This embeds the solution (mobile app) in the need statement.

✓ "Track cognitive performance objectively"

This is the actual need. Mobile app is one possible solution among many.

**4. Evidence-based or explicitly hypothesized**

**If validated:**
"Eliminate dependency on Chinese/Japanese imports"
*(Heard from 12/15 magnet manufacturers interviewed)*

**If hypothesis:**
"Enable 3D printing applications with spherical powders"
*[requires validation: only 2/15 manufacturers mentioned 3D printing interest]*

**Distribution guideline:**

Aim for:
- Tasks: 3-4 needs
- Pains: 3-4 needs
- Expectations: 3-4 needs

Don't force balance if data shows different patterns, but severe imbalance may indicate incomplete research.

---

### Section 4: EXISTING SOLUTIONS

**Purpose:** Map competitive landscape and identify opportunity gaps

**Structure:** Table with 3 columns

| Solution | Description | Limitations Identified |

**Quality standard:** 5-6 solutions, always include "Doing Nothing" as final row

#### Column 1: Solution Name/Type

**Guidelines:**
- Be specific: "Lumosity" not "brain training apps"
- Use brand names when possible
- Generic categories when needed: "Conventional High-Temperature Production"
- Always include: "Doing Nothing" or "Status Quo"

#### Column 2: Description (2-3 sentences)

**Include:**
1. What it is (product, service, process)
2. Who uses it (market share, geography)
3. How it works (key features, mechanism)

**Strong example:**
"Established global suppliers (primarily China) providing dense NdFeB alloy powders to Brazilian manufacturers. Dominant market solution with mature supply chains and competitive pricing due to economies of scale."

**What makes it strong:**
- Specific: names China, not "foreign suppliers"
- Market position: "dominant"
- Key advantage: "economies of scale"

#### Column 3: Limitations Identified (2-4 sentences)

**This is the most critical column.** It shows why your opportunity exists.

**Quality requirements:**
- **Specific** - not vague complaints
- **Evidence-based** - from user research or testing
- **Meaningful** - not trivial issues
- **Connected to needs** - explains unmet needs from Section 3

**Poor example:**
"Not very good. Users seem unhappy. Could be better."

**Strong example:**
"Trade barriers intensifying due to geopolitical tensions. No customization for Brazilian specifications. Supply chain vulnerable to export controls. Prices subject to international market volatility. No circular economy/recycling integration."

**What makes it strong:**
- Multiple specific limitations
- Connected to macro trends (geopolitics)
- Technical gap (no customization)
- Strategic vulnerability (export controls)

#### The "Doing Nothing" Row

**Always include this.** Status quo is a real competitor.

**Example:**

| Doing Nothing (Import Dependency Status Quo) | Organizations continue relying entirely on imported NdFeB powders and finished magnets. Current state for majority of Brazilian manufacturers and institutions. Inaction remains a choice. | Strategic vulnerability to trade disruptions. No control over specifications or pricing. Technology dependence on foreign suppliers. Incompatible with Brazil's strategic sovereignty goals. Limits domestic innovation in magnet applications. |

**Why this matters:** If you can't articulate why "doing nothing" is problematic, you don't have a compelling value proposition. Many people choose inaction if switching costs exceed perceived benefit.

#### Competitive Analysis Quality Checks

Before finalizing:
- [ ] Tested each solution yourself or interviewed users?
- [ ] Documented specific failures, not generic complaints?
- [ ] Included non-obvious substitutes, not just direct competitors?
- [ ] Validated users are actually dissatisfied?
- [ ] Included "doing nothing" with honest assessment?

**Common pitfalls:**

**Pitfall 1: Superficial research**

❌ "We looked at their website and it seems outdated."

✓ "Interviewed 8 users of Competitor X. 6/8 cited limited customization as reason for supplementing with alternative solutions. Documented specific instances where customization requests were declined."

**Pitfall 2: Missing non-obvious competitors**

Users seeking cognitive wellness might use:
- **Direct:** Brain training apps
- **Indirect:** Meditation apps, memory supplements
- **Substitute:** Physical exercise, social engagement
- **None:** Doing nothing (accepting decline)

**Map all of these.**

**Pitfall 3: Assuming dissatisfaction**

❌ Assumption: "Users must hate relying on imports"

✓ Validation: "8/15 manufacturers said import dependency is concerning but current pricing and reliability make switching risky without proven domestic alternative. Price premium tolerance: <15%"

This reveals the real barrier (switching risk > pain) and quantifies constraints.

---

### Section 5: EVIDENCE REQUIREMENTS & VALIDATION STATUS

**Purpose:** Explicitly separate facts from assumptions

**Why critical:** Most failed innovations build on unvalidated assumptions. This section forces early identification when validation is still cheap.

#### Current Evidence Base

**Strong Evidence (from project materials):**

List facts you can cite with sources.

**Examples:**
- "Global supermagnets market: >$15B annually (USGS 2024)"
- "Brazil imports 100% rare earth elements (MDIC trade data 2023-2024)"
- "TRL 4 achieved, validated lab results (CDTN report Nov 2025)"

**Weak Evidence (assumptions requiring validation):**

List logical assumptions lacking customer validation.

**Examples:**
- "Customer willingness to pay premium for domestic supply"
- "3D printing demand among Brazilian magnet producers"
- "Preference for customization vs. standardized products"

#### Critical Validation Gaps

**Prioritize by impact on business model:**

**High Priority [requires customer interviews]:**
Questions directly affecting viability

**Examples:**
1. Do manufacturers experience significant pain from import dependence?
2. What price premium would they pay for domestic supply?
3. Which segments face most urgent needs?

**Medium Priority [requires market research]:**
Questions answerable through secondary sources

**Examples:**
6. Addressable market size for Brazil specifically?
7. Required certifications and timeline/cost?
8. Growth projections for target sectors?

**Low Priority [can be refined later]:**
Nice-to-know details not affecting go/no-go

**Examples:**
11. Detailed decision processes per segment
12. Influencer mapping beyond direct buyers

---

### Sections 6-11: Strategic Analysis

These sections translate raw data into strategic insights and recommendations.

**Section 6: Requesters Reliability Assessment**

Synthesize overall validation confidence.

**Section 7: Integration with Business Model**

Connect requesters to revenue streams. Identify alignment and risks.

**Section 8: Competitive Positioning Insights**

Assess differentiation honestly (strong/uncertain/missing).

**Section 9: Recommendations for Immediate Action**

Three priorities with timeline, objective, success metrics.

**Section 10: Evidence-Based Validation Checklist**

Comprehensive checklist before claiming completion.

**Section 11: Conclusion - Path Forward**

Synthesize into clear strategic recommendation with go/no-go gates.

*(See Quick Start guide for detailed structure of each section)*

---

### Section 12: Customer Discovery Interview Guide

**Purpose:** Enable effective customer interviews

**Structure:** 5 interview phases + best practices + target segments

**Critical sequencing:** Understand needs (Phases 1-3) BEFORE pitching solution (Phase 5).

**Best practices summary:**
1. Listen More, Talk Less (80/20 rule)
2. Ask Open-Ended Questions
3. Dig Deeper with Follow-Ups
4. Listen for Problems, Not Solutions
5. Validate with Specifics
6. Don't Sell, Learn
7. End with Referrals

---

## EVIDENCE STANDARDS

### The Three Evidence Levels

**Level 1: Validated (High Confidence)**
- Multiple customer interviews (5+)
- Direct observation of behavior
- Documented usage data
- Pilot testing results

**Level 2: Preliminary (Medium Confidence)**
- Limited interviews (1-5)
- Secondary market research
- Expert opinion
- Competitor analysis

**Level 3: Hypothesis (Low Confidence)**
- Logical inference
- Internal team assumptions
- No direct validation

**Rule:** Always label evidence level. "Not yet interviewed" is valuable because it shows exactly where validation is needed.

### When Customer Interviews Are Required

**Mandatory for:**
- Validating needs exist and intensity
- Testing willingness to pay and pricing
- Understanding decision criteria
- Identifying real objections
- Confirming pain is greater than switching cost

**Not sufficient alone:**
- Customer interviews tell you what people say
- Must also observe what people do
- Pilot testing reveals actual behavior vs. stated intent

---

## QUALITY ASSURANCE

### Pre-Delivery Checklist

**Files:**
- [ ] Markdown analysis (.md)
- [ ] DOCX Part 1: Core Analysis
- [ ] DOCX Part 2: Strategic Analysis
- [ ] DOCX Part 3: Interview Guide

**Content:**
- [ ] 6-10 requesters with honest reliability ratings
- [ ] 10 needs, all ≤60 characters
- [ ] 5-6 solutions plus "Doing Nothing"
- [ ] Evidence gaps identified and prioritized
- [ ] 3 recommendations with specific metrics

**Quality:**
- [ ] Validation status is honest
- [ ] No fabricated interviews or data
- [ ] Recommendations are actionable
- [ ] Internal consistency across files
- [ ] Professional formatting applied

---

## PATTERNS AND PITFALLS

### Common Desirability Patterns

**Pattern 1: Strong Tech, Weak Market**
- High Legitimacy (4.0+)
- Low Desirability (unvalidated)

**Action:** Stop tech development. Start customer discovery.

**Pattern 2: Strong Needs, Wrong Requesters**
- Needs validated but targeting wrong segment
- Common in B2B (targeting users not buyers)

**Action:** Refine requester profiles. Distinguish users/buyers/influencers.

**Pattern 3: Validated Needs, Status Quo Wins**
- Customers acknowledge needs
- But existing solutions "good enough"

**Action:** Find higher-pain segment or dramatically improve value proposition (10x, not 10%).

---

## VIANEO INTEGRATION

### How Desirability Connects

**Legitimacy → Desirability**
Problem statement defines potential requesters

**Desirability → Acceptability**
Requesters become ecosystem stakeholders

**Desirability → Feasibility**
Validated needs define required functionality

**Desirability → Viability**
Need intensity correlates with willingness to pay

---

*This reference supports the Vianeo Business Model Evaluation Playbook, Desirability Assessment (25% weight).*

*Companion documents:*
*- Quick Start: `VIANEO_Desirability_Quick_Start.md`*
*- Execution Guide: `prompts/step_5_needs_requesters.md`*
*- Formatting Guide: `VIANEO_Document_Formatting_Guide.md`*

*Version: 2.0 | Updated: November 2025*
