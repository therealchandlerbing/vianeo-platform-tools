# STEP 2: 40-Question Diagnostic Assessment

**Time Required:** 30-45 minutes
**Output:** Two documents - (1) Assessment Results, (2) Score Summary
**Purpose:** Rapid comprehensive assessment across Team, Technology, Management, and Commercial dimensions

---

## Overview

Step 2 provides a structured diagnostic across four critical dimensions of startup readiness. This assessment identifies strengths and gaps before the detailed Market Maturity Assessment (Step 3).

**The 40 questions are organized as:**
- **Team (T1-T9):** 9 questions - People, expertise, commitment
- **Technology (Tech1-Tech11):** 11 questions - Innovation, development, IP
- **Management (M1-M12):** 12 questions - Strategy, operations, governance
- **Commercial (C1-C8):** 8 questions - Market, customers, business model

---

## Scoring Scale

Use this evidence-based rubric for all 40 questions:

| Score | Meaning | Evidence Required |
|-------|---------|------------------|
| **5** | **Complete** | External validation, documented evidence, multiple sources |
| **4** | **Strong** | Some external validation, clear capability, preliminary evidence |
| **3** | **Adequate** | Internal validation only, reasonable assumptions, basic capability |
| **2** | **Weak** | Significant gaps identified, aware but not addressed, concerning |
| **1** | **Critical Gap** | No evidence, major deficiency, not addressed, red flag |

---

## Special Response Types

In addition to the 1-5 scoring scale, the following special responses are allowed for specific situations:

### INSUFFICIENT DATA
**Use when:** Application materials do not provide enough information to score the question.
**Action:** Mark as "INSUFFICIENT DATA" and add to "Questions to Ask Founders" section.
**Example:** "T3: INSUFFICIENT DATA - No information on domain expertise in application."

### CONTEXTUAL NOTE
**Use when:** Score needs important qualification or explanation beyond standard evidence note.
**Format:** [Score] + CONTEXTUAL NOTE: [Explanation]
**Example:** "T9: Score 2 - CONTEXTUAL NOTE: Both founders plan to go full-time once seed funding is secured (Q2 2025)."

### YES/NO
**Use when:** Question is binary and score doesn't apply.
**Format:** YES or NO + brief explanation
**Example:** "Tech4: YES - Patent application filed December 2024 for core algorithm."

### N/A (Not Applicable)
**Use when:** Question is not relevant to this specific venture.
**Format:** N/A + brief justification
**Example:** "Tech4: N/A - Software platform with no patentable components; relying on trade secrets and first-mover advantage."

**Important:** Use special responses sparingly. Most questions should receive standard 1-5 scores.

---

## Instructions for AI Assistant

Evaluate this startup using the 40-question diagnostic framework. For each question:

1. **Score 1-5** using the scale above (or use special response if truly applicable)
2. **Provide brief evidence** citation or note gap
3. **Identify red flags** (any score of 1, multiple 2s in same dimension)
4. **Calculate dimension averages**
5. **Generate two documents**: Assessment Results + Score Summary
6. **List "Questions to Ask Founders"** for all INSUFFICIENT DATA responses

---

## DIMENSION 1: TEAM (9 Questions)

### T1. Technical Completeness of Team

**Question:** Does the team have all necessary technical skills to build the solution?

**Evidence to Look For:**
- Resume/background of technical team members
- Specific expertise matching technology requirements
- Previous products or projects built
- Technical advisors if gaps exist

**Scoring:**
- **5**: All technical roles filled with experienced people, proven track record
- **4**: Core technical skills present, minor gaps with plan to fill
- **3**: Basic technical capability, some key skills present
- **2**: Significant technical skill gaps, unclear how to address
- **1**: No technical capability or major skills missing

**Score:** ___

**Evidence/Gap:** ___

---

### T2. Previous Startup/Innovation Experience

**Question:** Do team members have prior startup or innovation experience?

**Evidence to Look For:**
- Previous startups founded or early employee roles
- Product launches or new venture creation
- Innovation projects in corporate settings
- Track record of 0-to-1 building

**Scoring:**
- **5**: Multiple team members with successful startup exits or major launches
- **4**: Core team has startup experience, at least one successful exit
- **3**: Some startup exposure, no exits but relevant experience
- **2**: Limited innovation experience, mostly corporate backgrounds
- **1**: No startup or innovation experience

**Score:** ___

**Evidence/Gap:** ___

---

### T3. Domain Expertise Depth

**Question:** Does the team have deep expertise in the problem domain?

**Evidence to Look For:**
- Years of experience in the industry
- Professional roles relevant to problem
- Domain-specific credentials or certifications
- Published work or thought leadership

**Scoring:**
- **5**: 10+ years domain experience, recognized experts, deep networks
- **4**: 5-10 years experience, strong domain knowledge and contacts
- **3**: 2-5 years experience, basic domain understanding
- **2**: <2 years experience, limited domain knowledge
- **1**: No domain expertise

**Score:** ___

**Evidence/Gap:** ___

---

### T4. Ability to Attract Talent

**Question:** Can the team attract and recruit necessary talent?

**Evidence to Look For:**
- Network in relevant talent pools
- Employer brand or reputation
- Previous successful hires
- Advisory board or letters of intent from candidates

**Scoring:**
- **5**: Strong employer brand, multiple candidates lined up, proven hiring
- **4**: Good network, some candidates identified, clear hiring plan
- **3**: Basic network, aware of where to find talent
- **2**: Limited network, unclear hiring strategy
- **1**: No ability to attract talent, no plan

**Score:** ___

**Evidence/Gap:** ___

---

### T5. Leadership and Vision Clarity

**Question:** Is there clear leadership with a compelling vision?

**Evidence to Look For:**
- Vision statement or north star
- Team alignment on direction
- Ability to communicate vision
- Strategic decisions demonstrating clarity

**Scoring:**
- **5**: Crystal clear vision, inspires team and stakeholders, documented
- **4**: Clear vision, good communication, mostly aligned team
- **3**: Basic vision exists, some alignment
- **2**: Vague vision, poor communication, misalignment
- **1**: No clear vision or leadership

**Score:** ___

**Evidence/Gap:** ___

---

### T6. Execution Capability Demonstrated

**Question:** Has the team demonstrated ability to execute and deliver?

**Evidence to Look For:**
- Milestones achieved on time
- Product/prototype delivered
- Commitments met to partners or customers
- Track record of shipping

**Scoring:**
- **5**: Consistent track record of on-time delivery, proven execution
- **4**: Good execution, most milestones met, minor delays
- **3**: Some execution demonstrated, mixed track record
- **2**: Poor execution, missed deadlines, undelivered commitments
- **1**: No execution capability demonstrated

**Score:** ___

**Evidence/Gap:** ___

---

### T7. Resilience and Adaptability Shown

**Question:** Has the team shown resilience and ability to adapt to challenges?

**Evidence to Look For:**
- Pivots made based on learning
- Recovery from setbacks
- Iteration based on feedback
- Continued progress despite obstacles

**Scoring:**
- **5**: Multiple pivots based on data, strong resilience, learns quickly
- **4**: At least one successful pivot, adapts to feedback
- **3**: Some adaptability, responds to major challenges
- **2**: Rigid thinking, resists change, slow to adapt
- **1**: No resilience or adaptability demonstrated

**Score:** ___

**Evidence/Gap:** ___

---

### T8. Network and Advisory Support

**Question:** Does the team have strong network and advisory support?

**Evidence to Look For:**
- Named advisors with relevant expertise
- Active mentors providing guidance
- Industry connections documented
- Letters of support from advisors

**Scoring:**
- **5**: Multiple active advisors with deep expertise and networks
- **4**: 2-3 advisors engaged, valuable connections
- **3**: 1-2 advisors, basic network support
- **2**: Advisors named but not active, weak network
- **1**: No advisors or network support

**Score:** ___

**Evidence/Gap:** ___

---

### T9. Commitment Level (Full-time/Part-time)

**Question:** Are team members full-time and fully committed to the venture?

**Evidence to Look For:**
- Employment status (full-time vs. part-time)
- Equity stakes showing commitment
- Sacrifices made (left jobs, relocated, etc.)
- Timeline for full-time transition

**Scoring:**
- **5**: All core team members full-time, significant equity, high commitment
- **4**: Most team full-time, clear timeline for rest, strong commitment
- **3**: Mix of full-time and part-time, commitment unclear
- **2**: Mostly part-time, low commitment signals
- **1**: No one full-time, side project mentality

**Score:** ___

**Evidence/Gap:** ___

---

### TEAM DIMENSION SUMMARY

**Average Score:** (Sum of T1-T9) / 9 = ___

**Key Strengths:**
- [Highest scoring areas, scores of 4-5]
- [Proven capabilities]

**Critical Gaps:**
- [Score 1 items requiring immediate attention]
- [Score 2 items showing weakness]

**Red Flags Identified:**
- [ ] Any score of 1 in Team dimension
- [ ] Three or more scores of 2
- [ ] No full-time commitment (T9 ≤ 2)

---

## DIMENSION 2: TECHNOLOGY (11 Questions)

### Tech1. Innovation Level vs. Existing Solutions

**Question:** How innovative is the technology compared to existing solutions?

**Evidence to Look For:**
- Competitive analysis showing differentiation
- Technical approach comparison
- Novel algorithms, processes, or methods
- Patent applications or IP

**Scoring:**
- **5**: Breakthrough innovation, 10x better, strong IP position
- **4**: Significant innovation, clearly differentiated, some IP
- **3**: Incremental innovation, better than alternatives
- **2**: Minimal innovation, "me too" solution
- **1**: No innovation, copies existing solutions

**Score:** ___

**Evidence/Gap:** ___

---

### Tech2. Technical Feasibility Validated

**Question:** Has technical feasibility been validated through prototypes or testing?

**Evidence to Look For:**
- Proof-of-concept completed
- Prototype working
- Technical validation from experts
- Performance testing results

**Scoring:**
- **5**: Full working prototype, validated by experts, proven feasible
- **4**: Working proof-of-concept, strong feasibility indicators
- **3**: Basic prototype, appears feasible but not fully validated
- **2**: Concept only, feasibility questionable
- **1**: No validation, feasibility unknown or doubtful

**Score:** ___

**Evidence/Gap:** ___

---

### Tech3. Prototype/MVP Development Stage

**Question:** What is the current stage of product development?

**Evidence to Look For:**
- Actual working product or prototype
- Screenshots or demo
- Technical architecture documented
- Code repository or development log

**Scoring:**
- **5**: Production-ready MVP, users using it, stable
- **4**: Working beta, most features complete, testing underway
- **3**: Alpha or early MVP, core features working
- **2**: Basic prototype, limited functionality
- **1**: Concept only, no working product

**Score:** ___

**Evidence/Gap:** ___

---

### Tech4. Intellectual Property Position

**Question:** Is intellectual property protected or protectable?

**Evidence to Look For:**
- Patent applications filed
- Trade secrets documented
- Copyright or trademark registrations
- Freedom-to-operate analysis

**Scoring:**
- **5**: Multiple patents granted, strong IP portfolio
- **4**: Patent applications filed, clear IP strategy
- **3**: IP identified and documented, plan to protect
- **2**: Some IP but unprotected, unclear strategy
- **1**: No IP or all in public domain

**Note:** For software/platforms without patentable components, N/A may be appropriate if trade secrets and first-mover advantage are the strategy.

**Score:** ___

**Evidence/Gap:** ___

---

### Tech5. Scalability of Technical Solution

**Question:** Can the technology scale to meet market demand?

**Evidence to Look For:**
- Architecture supports scaling
- Load testing or capacity planning
- Infrastructure strategy (cloud, etc.)
- Technical scalability analysis

**Scoring:**
- **5**: Proven scalability, architecture designed for 1000x growth
- **4**: Clear scaling path, infrastructure plan, some validation
- **3**: Scalability appears feasible, basic plan exists
- **2**: Scalability questionable, no clear approach
- **1**: Cannot scale, architecture limitations

**Score:** ___

**Evidence/Gap:** ___

---

### Tech6. Technical Risk Identification/Mitigation

**Question:** Are technical risks identified and mitigation strategies in place?

**Evidence to Look For:**
- Technical risk register
- Mitigation strategies documented
- Contingency plans
- Alternative approaches identified

**Scoring:**
- **5**: All risks identified, mitigation plans tested, contingencies ready
- **4**: Major risks identified, mitigation strategies defined
- **3**: Some risks identified, basic mitigation thinking
- **2**: Risks not well understood, no mitigation plans
- **1**: No risk assessment, unaware of technical challenges

**Score:** ___

**Evidence/Gap:** ___

---

### Tech7. Development Roadmap Clarity

**Question:** Is there a clear technical development roadmap with milestones?

**Evidence to Look For:**
- Product roadmap document
- Milestone definitions
- Timeline with dates
- Resource allocation plan

**Scoring:**
- **5**: Detailed roadmap, milestones with success criteria, resources allocated
- **4**: Clear roadmap, key milestones defined, realistic timeline
- **3**: Basic roadmap, major milestones identified
- **2**: Vague roadmap, unclear milestones, unrealistic timeline
- **1**: No roadmap or development plan

**Score:** ___

**Evidence/Gap:** ___

---

### Tech8. Technical Partnerships/Resources

**Question:** Are necessary technical partnerships or resources secured?

**Evidence to Look For:**
- API partnerships or integrations identified
- Cloud or infrastructure commitments
- Development tools or platforms
- Technical partners engaged

**Scoring:**
- **5**: All critical partnerships secured, agreements signed
- **4**: Key partnerships in discussion, likely to secure
- **3**: Partnerships identified, initial contact made
- **2**: Partnerships needed but not engaged
- **1**: No awareness of necessary partnerships

**Score:** ___

**Evidence/Gap:** ___

---

### Tech9. Security and Data Privacy Approach

**Question:** Are security and data privacy considerations addressed?

**Evidence to Look For:**
- Security architecture documented
- Data privacy compliance plan (GDPR, HIPAA, etc.)
- Security audits or assessments
- Incident response plan

**Scoring:**
- **5**: Comprehensive security architecture, compliance certified, audited
- **4**: Security plan documented, compliance path clear, basic implementation
- **3**: Security considerations identified, basic measures in place
- **2**: Minimal security thinking, compliance unclear
- **1**: No security or privacy considerations

**Note:** Particularly critical for healthcare, finance, education sectors.

**Score:** ___

**Evidence/Gap:** ___

---

### Tech10. Technology Stack Appropriateness

**Question:** Is the chosen technology stack appropriate for the solution and team capabilities?

**Evidence to Look For:**
- Technology choices justified
- Team expertise matches stack
- Maintainability and hiring considerations
- Performance requirements met

**Scoring:**
- **5**: Optimal stack choice, team expertise deep, well-justified
- **4**: Good stack choice, team competent, reasonable justification
- **3**: Adequate stack, team learning, basic justification
- **2**: Questionable stack choice, team lacking expertise
- **1**: Poor stack choice or no technical consideration

**Score:** ___

**Evidence/Gap:** ___

---

### Tech11. Quality Assurance and Testing

**Question:** Are quality assurance processes and testing practices in place?

**Evidence to Look For:**
- Testing methodology (unit, integration, user testing)
- QA processes documented
- Bug tracking and resolution
- Performance monitoring

**Scoring:**
- **5**: Comprehensive QA, automated testing, continuous monitoring
- **4**: Structured QA processes, regular testing, tracking in place
- **3**: Basic testing practices, some QA processes
- **2**: Minimal testing, ad-hoc QA
- **1**: No testing or QA processes

**Score:** ___

**Evidence/Gap:** ___

---

### TECHNOLOGY DIMENSION SUMMARY

**Average Score:** (Sum of Tech1-Tech11) / 11 = ___

**Key Strengths:**
- [Highest scoring areas, scores of 4-5]
- [Proven technical capabilities]

**Critical Gaps:**
- [Score 1 items requiring immediate attention]
- [Score 2 items showing weakness]

**Red Flags Identified:**
- [ ] Any score of 1 in Technology dimension
- [ ] Feasibility not validated (Tech2 = 1)
- [ ] No working prototype (Tech3 ≤ 2)
- [ ] Security/privacy not addressed for regulated sector (Tech9 ≤ 2)

---

## DIMENSION 3: MANAGEMENT (12 Questions)

### M1. Strategy Clarity and Communication

**Question:** Is there a clear, well-articulated strategy?

**Evidence to Look For:**
- Written strategy document
- Clear objectives and goals
- Strategic priorities defined
- Team understanding and alignment

**Scoring:**
- **5**: Comprehensive strategy, documented, team fully aligned
- **4**: Clear strategy, mostly documented, good team understanding
- **3**: Basic strategy exists, some documentation
- **2**: Vague strategy, poor documentation, limited alignment
- **1**: No clear strategy

**Score:** ___

**Evidence/Gap:** ___

---

### M2. Market Understanding Depth

**Question:** Does the team demonstrate deep understanding of their target market?

**Evidence to Look For:**
- Market research conducted
- Customer segments clearly defined
- Competitive landscape analysis
- Market dynamics and trends understood

**Scoring:**
- **5**: Deep market knowledge, extensive research, clear segmentation
- **4**: Good market understanding, solid research, segments identified
- **3**: Basic market knowledge, some research conducted
- **2**: Limited market understanding, minimal research
- **1**: No market understanding or research

**Score:** ___

**Evidence/Gap:** ___

---

### M3. Financial Planning Sophistication

**Question:** Is there sophisticated financial planning and forecasting?

**Evidence to Look For:**
- Financial model with assumptions documented
- Revenue and expense projections
- Cash flow forecasting
- Scenario planning (base/upside/downside)

**Scoring:**
- **5**: Comprehensive financial model, scenarios, assumptions validated
- **4**: Solid financial plan, projections reasonable, basic scenarios
- **3**: Basic financial projections, assumptions documented
- **2**: Rudimentary financial planning, unrealistic assumptions
- **1**: No financial planning or projections

**Score:** ___

**Evidence/Gap:** ___

---

### M4. Risk Management Approach

**Question:** Are risks identified and mitigation strategies in place?

**Evidence to Look For:**
- Risk register or assessment
- Mitigation strategies for major risks
- Contingency planning
- Regular risk review process

**Scoring:**
- **5**: Comprehensive risk management, regular reviews, contingencies ready
- **4**: Major risks identified, mitigation strategies defined
- **3**: Some risks identified, basic mitigation thinking
- **2**: Limited risk awareness, no mitigation plans
- **1**: No risk management

**Score:** ___

**Evidence/Gap:** ___

---

### M5. Operational Planning Quality

**Question:** Is there clear operational planning for execution?

**Evidence to Look For:**
- Operational plan or playbook
- Resource allocation defined
- Process documentation
- Operational metrics tracked

**Scoring:**
- **5**: Comprehensive operations plan, processes documented, metrics tracked
- **4**: Clear operations plan, key processes defined
- **3**: Basic operational planning, some processes
- **2**: Limited operational planning, ad-hoc processes
- **1**: No operational planning

**Score:** ___

**Evidence/Gap:** ___

---

### M6. Milestone Setting and Tracking

**Question:** Are clear milestones set and tracked?

**Evidence to Look For:**
- Milestones defined with success criteria
- Timeline with dates
- Progress tracking mechanism
- Historical milestone achievement

**Scoring:**
- **5**: Clear milestones, tracked systematically, consistently achieved
- **4**: Milestones defined, tracking in place, mostly achieved
- **3**: Basic milestones, some tracking
- **2**: Vague milestones, no tracking, often missed
- **1**: No milestones or tracking

**Score:** ___

**Evidence/Gap:** ___

---

### M7. Resource Allocation Efficiency

**Question:** Are resources allocated efficiently to priorities?

**Evidence to Look For:**
- Resource allocation decisions documented
- Alignment with strategic priorities
- Efficiency metrics or ROI analysis
- Reallocation based on learning

**Scoring:**
- **5**: Optimal allocation, data-driven decisions, regular optimization
- **4**: Good allocation, mostly aligned with priorities
- **3**: Adequate allocation, basic alignment
- **2**: Poor allocation, misaligned with priorities
- **1**: No conscious resource allocation

**Score:** ___

**Evidence/Gap:** ___

---

### M8. Decision-Making Process

**Question:** Is there a clear, effective decision-making process?

**Evidence to Look For:**
- Decision-making framework documented
- Roles and authorities clear
- Data-driven approach
- Speed of decision-making appropriate

**Scoring:**
- **5**: Excellent decision process, data-driven, clear accountabilities, fast
- **4**: Good decision process, mostly data-driven, clear roles
- **3**: Basic decision process, some structure
- **2**: Poor decision process, slow or reactive
- **1**: No clear decision-making process

**Score:** ___

**Evidence/Gap:** ___

---

### M9. Stakeholder Management

**Question:** Are key stakeholders identified and relationships managed?

**Evidence to Look For:**
- Stakeholder map or register
- Engagement strategies per stakeholder
- Communication plan
- Relationship health tracked

**Scoring:**
- **5**: Comprehensive stakeholder management, systematic engagement
- **4**: Key stakeholders identified, engagement plans in place
- **3**: Basic stakeholder awareness, some engagement
- **2**: Limited stakeholder management
- **1**: No stakeholder management

**Score:** ___

**Evidence/Gap:** ___

---

### M10. Culture and Values Definition

**Question:** Are organizational culture and values clearly defined?

**Evidence to Look For:**
- Values documented and communicated
- Culture intentionally shaped
- Hiring aligned with culture
- Cultural practices evidence

**Scoring:**
- **5**: Strong culture, values lived, intentionally reinforced
- **4**: Culture defined, values clear, mostly practiced
- **3**: Basic values, emerging culture
- **2**: Vague culture, values not clear
- **1**: No defined culture or values

**Score:** ___

**Evidence/Gap:** ___

---

### M11. Learning and Iteration Speed

**Question:** Does the team learn quickly and iterate based on data?

**Evidence to Look For:**
- Experimentation approach
- Metrics tracked and reviewed
- Pivots or iterations based on learning
- Feedback loops established

**Scoring:**
- **5**: Rapid learning cycles, systematic experimentation, data-driven pivots
- **4**: Good learning cadence, regular iterations, mostly data-driven
- **3**: Some learning and iteration, basic data use
- **2**: Slow learning, infrequent iterations, limited data use
- **1**: No learning or iteration demonstrated

**Score:** ___

**Evidence/Gap:** ___

---

### M12. Governance Structure

**Question:** Is there appropriate governance structure for current stage?

**Evidence to Look For:**
- Board or advisory board composition
- Governance policies (if applicable)
- Meeting cadence and structure
- Accountability mechanisms

**Scoring:**
- **5**: Strong governance, appropriate board, clear policies, accountability
- **4**: Good governance structure, board in place, basic policies
- **3**: Basic governance, advisory board or informal structure
- **2**: Minimal governance, unclear structure
- **1**: No governance structure

**Note:** Expectations scale with stage. Early-stage may be Score 3 with advisory board.

**Score:** ___

**Evidence/Gap:** ___

---

### MANAGEMENT DIMENSION SUMMARY

**Average Score:** (Sum of M1-M12) / 12 = ___

**Key Strengths:**
- [Highest scoring areas, scores of 4-5]
- [Proven management capabilities]

**Critical Gaps:**
- [Score 1 items requiring immediate attention]
- [Score 2 items showing weakness]

**Red Flags Identified:**
- [ ] Any score of 1 in Management dimension
- [ ] No clear strategy (M1 ≤ 2)
- [ ] Poor financial planning (M3 ≤ 2)
- [ ] No milestone tracking (M6 ≤ 2)

---

## DIMENSION 4: COMMERCIAL (8 Questions)

### C1. Customer Validation Depth

**Question:** How extensively have target customers been engaged and validated?

**Evidence to Look For:**
- Number of customer discovery interviews
- Depth of customer understanding
- Validation of problem and solution
- Customer segments clearly defined

**Scoring:**
- **5**: 50+ interviews, deep validation, multiple segments validated
- **4**: 20-49 interviews, good validation, key segments validated
- **3**: 10-19 interviews, basic validation, primary segment validated
- **2**: 5-9 interviews, limited validation
- **1**: <5 interviews, no meaningful validation

**Score:** ___

**Evidence/Gap:** ___

---

### C2. Market Size Quantification

**Question:** Is the market size quantified with defensible methodology?

**Evidence to Look For:**
- TAM/SAM/SOM calculated
- Sizing methodology documented (bottom-up/top-down/comparable)
- Assumptions stated and sourced
- Initial target market specified

**Scoring:**
- **5**: Rigorous sizing, multiple methodologies, validated assumptions
- **4**: Good sizing, clear methodology, reasonable assumptions
- **3**: Basic sizing, methodology stated, assumptions documented
- **2**: Rough sizing, unclear methodology, questionable assumptions
- **1**: No market sizing or completely unsupported

**Score:** ___

**Evidence/Gap:** ___

---

### C3. Business Model Clarity

**Question:** Is the business model clearly defined and articulated?

**Evidence to Look For:**
- Business model canvas or equivalent
- Value proposition clear
- Revenue streams defined
- Cost structure understood

**Scoring:**
- **5**: Comprehensive business model, fully articulated, validated
- **4**: Clear business model, well-documented, preliminary validation
- **3**: Basic business model, core elements defined
- **2**: Vague business model, elements unclear
- **1**: No clear business model

**Score:** ___

**Evidence/Gap:** ___

---

### C4. Revenue Model Validation

**Question:** Has the revenue model been tested with actual customers?

**Evidence to Look For:**
- Pricing tested with customers
- Paying customers or pilots with payment commitment
- Willingness to pay validated
- Payment terms tested

**Scoring:**
- **5**: Multiple paying customers, pricing validated at scale
- **4**: First paying customers, pricing validated with 10+ prospects
- **3**: Pricing tested with 5-10 customers, positive signals
- **2**: Pricing discussed with 1-4 customers, limited feedback
- **1**: No pricing validation with customers

**Score:** ___

**Evidence/Gap:** ___

---

### C5. Sales and Marketing Strategy

**Question:** Is there a clear, realistic sales and marketing strategy?

**Evidence to Look For:**
- Go-to-market plan documented
- Customer acquisition channels identified and tested
- Sales process defined
- Marketing plan with budget and tactics

**Scoring:**
- **5**: Comprehensive GTM strategy, channels validated, proven CAC
- **4**: Clear GTM strategy, channels identified, CAC estimates
- **3**: Basic sales/marketing plan, channels identified
- **2**: Vague sales/marketing approach, untested channels
- **1**: No sales or marketing strategy

**Score:** ___

**Evidence/Gap:** ___

---

### C6. Partnership Development

**Question:** Are strategic partnerships identified and being developed?

**Evidence to Look For:**
- Partnership strategy defined
- Key partners identified
- Engagement or discussions underway
- MOUs, LOIs, or contracts

**Scoring:**
- **5**: Critical partnerships secured with contracts
- **4**: Key partnerships in advanced discussions, LOIs signed
- **3**: Partnerships identified, initial discussions underway
- **2**: Partnerships needed but minimal progress
- **1**: No partnership strategy or development

**Score:** ___

**Evidence/Gap:** ___

---

### C7. Competitive Positioning

**Question:** Is competitive positioning clearly understood and differentiated?

**Evidence to Look For:**
- Competitive analysis completed
- Key competitors identified
- Differentiation clearly articulated
- Competitive advantages defensible

**Scoring:**
- **5**: Deep competitive intelligence, clear differentiation, sustainable advantages
- **4**: Good competitive analysis, differentiation articulated, some advantages
- **3**: Basic competitive understanding, differentiation stated
- **2**: Limited competitive analysis, weak differentiation
- **1**: No competitive analysis or differentiation

**Score:** ___

**Evidence/Gap:** ___

---

### C8. Growth Strategy Definition

**Question:** Is there a clear strategy for growth and scaling?

**Evidence to Look For:**
- Growth strategy documented
- Expansion plan (geographic, segment, product)
- Scaling milestones defined
- Resource requirements for growth understood

**Scoring:**
- **5**: Comprehensive growth strategy, clear milestones, resources planned
- **4**: Clear growth strategy, key milestones, resource needs identified
- **3**: Basic growth thinking, some milestones
- **2**: Vague growth plans, no clear path
- **1**: No growth strategy

**Score:** ___

**Evidence/Gap:** ___

---

### COMMERCIAL DIMENSION SUMMARY

**Average Score:** (Sum of C1-C8) / 8 = ___

**Key Strengths:**
- [Highest scoring areas, scores of 4-5]
- [Proven commercial capabilities]

**Critical Gaps:**
- [Score 1 items requiring immediate attention]
- [Score 2 items showing weakness]

**Red Flags Identified:**
- [ ] Any score of 1 in Commercial dimension
- [ ] No customer validation (C1 ≤ 2)
- [ ] Business model unclear (C3 ≤ 2)
- [ ] No revenue model validation (C4 ≤ 2)
- [ ] Market size unknown (C2 = 1)

---

## DOCUMENT 1: ASSESSMENT RESULTS

Generate the first document with this structure:

---

# 40-Question Diagnostic Assessment: [Company Name]

**Evaluation Date:** [YYYY-MM-DD]
**Evaluator:** [Name/Organization]
**Project Stage:** [From Step 0 Maturity Stage]

---

## ASSESSMENT OVERVIEW

**Total Questions Scored:** [#/40]
**Questions with INSUFFICIENT DATA:** [#]
**Questions with N/A:** [#]

---

## DIMENSIONAL SCORES

| Dimension | Score | Status | Questions Scored | Key Gaps |
|-----------|-------|--------|------------------|----------|
| **Team** (T1-T9) | X.XX / 5.0 | [STRONG/ADEQUATE/CONCERN/CRITICAL] | [#/9] | [List main gaps] |
| **Technology** (Tech1-Tech11) | X.XX / 5.0 | [STRONG/ADEQUATE/CONCERN/CRITICAL] | [#/11] | [List main gaps] |
| **Management** (M1-M12) | X.XX / 5.0 | [STRONG/ADEQUATE/CONCERN/CRITICAL] | [#/12] | [List main gaps] |
| **Commercial** (C1-C8) | X.XX / 5.0 | [STRONG/ADEQUATE/CONCERN/CRITICAL] | [#/8] | [List main gaps] |

**Status Thresholds:**
- **STRONG**: Score ≥ 4.0
- **ADEQUATE**: Score 3.0-3.9
- **CONCERN**: Score 2.0-2.9
- **CRITICAL**: Score < 2.0

---

## DETAILED SCORES BY DIMENSION

### TEAM DIMENSION (T1-T9)

| Question | Score | Evidence/Gap |
|----------|-------|--------------|
| T1: Technical Completeness | [1-5 or special] | [Evidence or gap description] |
| T2: Startup Experience | [1-5 or special] | [Evidence or gap description] |
| T3: Domain Expertise | [1-5 or special] | [Evidence or gap description] |
| T4: Talent Attraction | [1-5 or special] | [Evidence or gap description] |
| T5: Leadership/Vision | [1-5 or special] | [Evidence or gap description] |
| T6: Execution Capability | [1-5 or special] | [Evidence or gap description] |
| T7: Resilience/Adaptability | [1-5 or special] | [Evidence or gap description] |
| T8: Network/Advisory | [1-5 or special] | [Evidence or gap description] |
| T9: Commitment Level | [1-5 or special] | [Evidence or gap description] |

**Team Average:** [X.XX]

---

### TECHNOLOGY DIMENSION (Tech1-Tech11)

| Question | Score | Evidence/Gap |
|----------|-------|--------------|
| Tech1: Innovation Level | [1-5 or special] | [Evidence or gap description] |
| Tech2: Feasibility Validated | [1-5 or special] | [Evidence or gap description] |
| Tech3: Development Stage | [1-5 or special] | [Evidence or gap description] |
| Tech4: IP Position | [1-5 or special] | [Evidence or gap description] |
| Tech5: Scalability | [1-5 or special] | [Evidence or gap description] |
| Tech6: Risk Mitigation | [1-5 or special] | [Evidence or gap description] |
| Tech7: Roadmap Clarity | [1-5 or special] | [Evidence or gap description] |
| Tech8: Partnerships/Resources | [1-5 or special] | [Evidence or gap description] |
| Tech9: Security/Privacy | [1-5 or special] | [Evidence or gap description] |
| Tech10: Tech Stack | [1-5 or special] | [Evidence or gap description] |
| Tech11: QA/Testing | [1-5 or special] | [Evidence or gap description] |

**Technology Average:** [X.XX]

---

### MANAGEMENT DIMENSION (M1-M12)

| Question | Score | Evidence/Gap |
|----------|-------|--------------|
| M1: Strategy Clarity | [1-5 or special] | [Evidence or gap description] |
| M2: Market Understanding | [1-5 or special] | [Evidence or gap description] |
| M3: Financial Planning | [1-5 or special] | [Evidence or gap description] |
| M4: Risk Management | [1-5 or special] | [Evidence or gap description] |
| M5: Operational Planning | [1-5 or special] | [Evidence or gap description] |
| M6: Milestone Tracking | [1-5 or special] | [Evidence or gap description] |
| M7: Resource Allocation | [1-5 or special] | [Evidence or gap description] |
| M8: Decision-Making | [1-5 or special] | [Evidence or gap description] |
| M9: Stakeholder Mgmt | [1-5 or special] | [Evidence or gap description] |
| M10: Culture/Values | [1-5 or special] | [Evidence or gap description] |
| M11: Learning/Iteration | [1-5 or special] | [Evidence or gap description] |
| M12: Governance | [1-5 or special] | [Evidence or gap description] |

**Management Average:** [X.XX]

---

### COMMERCIAL DIMENSION (C1-C8)

| Question | Score | Evidence/Gap |
|----------|-------|--------------|
| C1: Customer Validation | [1-5 or special] | [Evidence or gap description] |
| C2: Market Size | [1-5 or special] | [Evidence or gap description] |
| C3: Business Model Clarity | [1-5 or special] | [Evidence or gap description] |
| C4: Revenue Validation | [1-5 or special] | [Evidence or gap description] |
| C5: Sales/Marketing Strategy | [1-5 or special] | [Evidence or gap description] |
| C6: Partnership Development | [1-5 or special] | [Evidence or gap description] |
| C7: Competitive Positioning | [1-5 or special] | [Evidence or gap description] |
| C8: Growth Strategy | [1-5 or special] | [Evidence or gap description] |

**Commercial Average:** [X.XX]

---

## TOP STRENGTHS (Scores 4-5)

1. **[Question ID]:** [Score] - [Brief description of strength and why it matters]
2. **[Question ID]:** [Score] - [Brief description of strength and why it matters]
3. **[Question ID]:** [Score] - [Brief description of strength and why it matters]
4. **[Question ID]:** [Score] - [Brief description of strength and why it matters]
5. **[Question ID]:** [Score] - [Brief description of strength and why it matters]

---

## CRITICAL GAPS (Scores 1)

1. **[Question ID]:** [Gap description] - **Why Critical:** [Explanation of risk/impact]
2. **[Question ID]:** [Gap description] - **Why Critical:** [Explanation of risk/impact]
3. **[Question ID]:** [Gap description] - **Why Critical:** [Explanation of risk/impact]

**If no Score 1 items:** "No critical gaps identified."

---

## MAJOR WEAKNESSES (Scores 2)

1. **[Question ID]:** [Weakness description] - **Concern:** [Why this is problematic]
2. **[Question ID]:** [Weakness description] - **Concern:** [Why this is problematic]
3. **[Question ID]:** [Weakness description] - **Concern:** [Why this is problematic]

**If no Score 2 items:** "No major weaknesses identified."

---

## RED FLAGS IDENTIFIED

Check all that apply:

**Team Dimension:**
- [ ] No full-time commitment (T9 ≤ 2)
- [ ] No domain expertise (T3 ≤ 2)
- [ ] No technical capability (T1 ≤ 2)
- [ ] Poor execution track record (T6 ≤ 2)

**Technology Dimension:**
- [ ] Technical feasibility unproven (Tech2 = 1)
- [ ] No working prototype (Tech3 ≤ 2)
- [ ] Cannot scale (Tech5 ≤ 2)
- [ ] Security/privacy not addressed in regulated sector (Tech9 ≤ 2)

**Management Dimension:**
- [ ] No clear strategy (M1 ≤ 2)
- [ ] Poor financial planning (M3 ≤ 2)
- [ ] No milestone tracking (M6 ≤ 2)
- [ ] No learning/iteration (M11 ≤ 2)

**Commercial Dimension:**
- [ ] No customer validation (C1 ≤ 2)
- [ ] Business model unclear (C3 ≤ 2)
- [ ] Revenue model untested (C4 ≤ 2)
- [ ] Market size unknown (C2 = 1)
- [ ] No competitive analysis (C7 ≤ 2)

---

## QUESTIONS TO ASK FOUNDERS

**Items Marked as INSUFFICIENT DATA:**

1. **[Question ID]:** [Specific question to ask]
2. **[Question ID]:** [Specific question to ask]
3. **[Question ID]:** [Specific question to ask]

**Follow-up Questions Based on Gaps:**

1. **[Related to specific gap]:** [Question]
2. **[Related to specific gap]:** [Question]
3. **[Related to specific gap]:** [Question]

**Validation Requests:**

1. **[Related to claim needing validation]:** [What evidence to request]
2. **[Related to claim needing validation]:** [What evidence to request]

---

## OVERALL NARRATIVE ASSESSMENT

[3-5 paragraph narrative covering:]

**Paragraph 1: Overall Readiness**
[Summary of overall readiness across dimensions, noting strongest and weakest areas]

**Paragraph 2: Key Strengths Pattern**
[Discuss pattern of strengths - is this a strong team with weak market validation? Strong tech with execution concerns? Identify the core strength areas.]

**Paragraph 3: Critical Risks and Gaps**
[Discuss most critical risks identified through gaps, red flags, and low scores. Prioritize by impact and urgency.]

**Paragraph 4: Stage Appropriateness**
[Assess whether scores are appropriate for current stage. Early-stage ventures naturally have lower Management scores. Are gaps concerning for this stage or expected?]

**Paragraph 5: Recommendation for Next Steps**
[Based on assessment, recommend: (1) Proceed to Step 3 Market Maturity, (2) Request additional information before proceeding, (3) Consider non-viable if critical gaps across dimensions, (4) Conditional proceed with specific milestones needed]

---

**End of Document 1**

---

## DOCUMENT 2: SCORE SUMMARY

Generate the second document (short-form summary) with this structure:

---

# 40-Question Diagnostic Score Summary

**Company:** [Name]
**Date:** [YYYY-MM-DD]
**Evaluator:** [Name]

---

## EXECUTIVE SUMMARY

[2-3 paragraph executive summary covering: overall assessment, key strengths, critical gaps, recommendation]

---

## DIMENSIONAL SCORES

| Dimension | Score | Status | Key Finding |
|-----------|-------|--------|-------------|
| Team | X.XX / 5.0 | [STATUS] | [One-line key finding] |
| Technology | X.XX / 5.0 | [STATUS] | [One-line key finding] |
| Management | X.XX / 5.0 | [STATUS] | [One-line key finding] |
| Commercial | X.XX / 5.0 | [STATUS] | [One-line key finding] |

**Overall Assessment:** [STRONG / ADEQUATE / CONCERNS / CRITICAL GAPS]

---

## TOP 5 STRENGTHS

1. [Question ID]: [Strength]
2. [Question ID]: [Strength]
3. [Question ID]: [Strength]
4. [Question ID]: [Strength]
5. [Question ID]: [Strength]

---

## TOP 5 GAPS/CONCERNS

1. [Question ID] (Score [X]): [Gap and why it matters]
2. [Question ID] (Score [X]): [Gap and why it matters]
3. [Question ID] (Score [X]): [Gap and why it matters]
4. [Question ID] (Score [X]): [Gap and why it matters]
5. [Question ID] (Score [X]): [Gap and why it matters]

---

## RED FLAGS

[List all checked red flags from Document 1, or state "None identified"]

---

## STRATEGIC RECOMMENDATIONS

**Immediate Actions Required:**
1. [Action based on critical gaps]
2. [Action based on critical gaps]
3. [Action based on critical gaps]

**Medium-term Priorities:**
1. [Action based on score 2 items]
2. [Action based on score 2 items]

**Questions for Founders:**
1. [Top 3 most critical questions from INSUFFICIENT DATA and gaps]
2. [Question]
3. [Question]

---

## RECOMMENDATION

**Overall Assessment:** [Choose one]
- [ ] **PROCEED TO STEP 3** - Strong or adequate across dimensions, ready for Market Maturity Assessment
- [ ] **CONDITIONAL PROCEED** - Address [specific gaps] before Step 3, or proceed with caveats
- [ ] **REQUEST ADDITIONAL INFO** - Too many INSUFFICIENT DATA items, need more information
- [ ] **SIGNIFICANT CONCERNS** - Multiple critical gaps, recommend validation sprint before proceeding
- [ ] **NON-VIABLE** - Critical gaps across multiple dimensions suggest fundamental issues

**Justification:**
[2-3 sentences explaining the recommendation based on scores and gaps]

**Next Steps:**
[Specific next actions - proceed to Step 3, request information on X/Y/Z, schedule founder interview, etc.]

---

**End of Document 2**

---

## OUTPUT FILES

Save both documents:

1. **Assessment Results (comprehensive):**
   - File name: `[CompanyName]_[Date]_02_Diagnostic_Results.md`
   - Convert to: `[CompanyName]_[Date]_02_Diagnostic_Results.docx`

2. **Score Summary (executive brief):**
   - File name: `[CompanyName]_[Date]_02_Diagnostic_Summary.md`
   - Convert to: `[CompanyName]_[Date]_02_Diagnostic_Summary.docx`

**Examples:**
- `HealthTech_2025-01-15_02_Diagnostic_Results.md`
- `HealthTech_2025-01-15_02_Diagnostic_Summary.docx`

---

## NEXT STEPS AFTER STEP 2

1. **Review both documents** for consistency and completeness
2. **Address INSUFFICIENT DATA** - Request additional information from founders
3. **Use "Questions to Ask Founders"** - Schedule interview if needed
4. **Proceed to Step 3** - 29-Question Market Maturity Assessment (if scores adequate)
5. **OR request validation** - If critical gaps require evidence before proceeding

**Estimated Time:** 30-45 minutes for complete assessment

---

## QUALITY CHECKS

Before finalizing:

- [ ] All 40 questions scored or marked with special response
- [ ] Evidence/gap provided for each score
- [ ] All dimension averages calculated correctly
- [ ] Red flags identified and checked
- [ ] "Questions to Ask Founders" list compiled
- [ ] Overall narrative assessment provided (3-5 paragraphs)
- [ ] Both documents generated (Results + Summary)
- [ ] Recommendation is specific and justified
- [ ] Files saved with proper naming convention

---

**Ready to assess your first startup? Provide application materials and Executive Brief (from Step 0) to begin the 40-question diagnostic.**
